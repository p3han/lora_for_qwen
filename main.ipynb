{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境自检：PyTorch + CUDA\n",
    "import torch, platform, os, sys, subprocess, datetime\n",
    "print(f\"[时间] {datetime.datetime.now()}\")\n",
    "print(f\"[Python] {sys.version.split()[0]}  ({platform.platform()})\")\n",
    "print(f\"[Torch]  {torch.__version__}\")\n",
    "print(f\"[CUDA]   可用 = {torch.cuda.is_available()} | 版本 = {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_properties(0)\n",
    "    print(f\"[GPU]    {gpu.name}  显存 {gpu.total_memory/1024**3:.1f} GB\")\n",
    "\n",
    "# 简单张量运算，验证 GPU 能跑 FP16\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.randn(8_000_000, device=\"cuda\", dtype=torch.float16)\n",
    "    y = x * 2 + 1\n",
    "    print(\"Tensor OK ‼️  均值:\", y.mean().item())\n",
    "else:\n",
    "    print(\"⚠️ 没检测到 GPU，检查显卡驱动 / CUDA Toolkit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch, os\n",
    "\n",
    "# 如果你之前 `setx HF_HOME D:\\hf_cache`，下面不需要额外指定 cache_dir；\n",
    "# 否则手动加 cache_dir=\"D:/hf_cache\"\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",         # 自动把 0.5B 丢到 GPU 0\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "prompt = \"请用一句话告诉我 PromptCBLUE 数据集是做什么的？\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "gen_ids = model.generate(**inputs, max_new_tokens=64, do_sample=False)\n",
    "print(tokenizer.decode(gen_ids[0, inputs['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LoRA fine-tune Qwen-0.5B with BF16 ===\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM,\n",
    "                          TrainingArguments, Trainer,\n",
    "                          DataCollatorForLanguageModeling)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch, os\n",
    "\n",
    "# 0) 基座模型（一次就够，如果上面已经加载就复用）\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,     # *** 关键：直接用 BF16 权重 ***\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 1) 读数据并拼 Prompt\n",
    "def concat(example):\n",
    "    example[\"text\"] = example[\"instruction\"] + \"\\n\" + example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "    return example\n",
    "\n",
    "raw_ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\":\"./processed/train_top_task.jsonl\",\n",
    "        \"validation\":\"./processed/dev_converted.jsonl\"\n",
    "    }\n",
    ").map(concat)\n",
    "\n",
    "# 2) Tokenize -> ids\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=1024)\n",
    "tok_ds = raw_ds.map(tok_fn, batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# 3) LoRA 适配器\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16, target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# 4) 训练参数 —— 用 bf16，关闭 fp16\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"lora_ckpt\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,                # ⭐ 开启 BF16\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"adamw_torch_fused\"  # PyTorch 自带 fused AdamW，更稳\n",
    ")\n",
    "\n",
    "# 5) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# 6) 保存适配器\n",
    "trainer.save_model(\"lora_ckpt/final\")\n",
    "tokenizer.save_pretrained(\"lora_ckpt/final\")\n",
    "print(\"✅ LoRA + BF16 训练完成，权重在 lora_ckpt/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 合并 LoRA + 基座权重，得到可独立推理模型 ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch, os, shutil\n",
    "\n",
    "# 1) 路径配置\n",
    "base_model_id   = \"Qwen/Qwen2.5-0.5B-Instruct\"   # 原始基座\n",
    "lora_adapter_dir = \"lora_ckpt/final\"             # 训练完的 LoRA 目录\n",
    "merged_dir       = \"qwen05_promptcblue_merged\"   # 要保存的新目录\n",
    "\n",
    "# 2) 加载基座 & LoRA\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, lora_adapter_dir)\n",
    "print(\"🔄 开始合并 LoRA 权重 …\")\n",
    "model = model.merge_and_unload()   # ⭐ 一步到位\n",
    "\n",
    "# 3) 保存（含 tokenizer）\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "print(f\"✅ 已保存到 {merged_dir}\")\n",
    "\n",
    "# 4) （可选）快速 sanity check 推理\n",
    "prompt = \"患者出现咳嗽、发热、呼吸困难，应考虑哪种最可能的初步诊断？\"\n",
    "ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"🗣️ 推理结果:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# PromptCBLUE — SAFE 单条推理，绝不会 OOM\n",
    "# ================================================\n",
    "import os, json, re, gc, tqdm, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_DIR  = \"qwen05_promptcblue_merged\"\n",
    "TEST_FILE  = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH  = \"predictions_full.jsonl\"\n",
    "MAX_NEW_TOK = 128\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side = \"left\"\n",
    "tok.pad_token = tok.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16,     # bf16 占用低且稳定\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "with open(TEST_FILE, encoding=\"utf8\") as f_in, \\\n",
    "     open(SAVE_PATH, \"w\", encoding=\"utf8\") as f_out, \\\n",
    "     torch.no_grad():\n",
    "    \n",
    "    for line in tqdm.tqdm(f_in, total=sum(1 for _ in open(TEST_FILE, encoding=\"utf8\")), desc=\"Gen\"):\n",
    "        j = json.loads(line)\n",
    "        \n",
    "        prompt = j[\"instruction\"] + \"\\n\" + j[\"input\"]\n",
    "        toks   = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        out_ids= model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "        ans    = tok.decode(out_ids[0, toks[\"input_ids\"].shape[1]:],\n",
    "                            skip_special_tokens=True).strip()\n",
    "        ans    = re.sub(r\"^(好的[,，]?\\s*|答[:：]?\\s*)\", \"\", ans)  # 去客套前缀\n",
    "\n",
    "        f_out.write(json.dumps({\"id\": j[\"id\"], \"prediction\": ans},\n",
    "                               ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # 立即释放本条显存，防碎片\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(f\"✅ 全量预测已写入 {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3429ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PromptCBLUE 预测 — OOM-SAFE + GPU 吞吐最大化  (batch=8→1)\n",
    "# ==========================================================\n",
    "import os, json, re, gc, tqdm, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# -------- 基本配置 --------\n",
    "MODEL_DIR   = \"qwen05_promptcblue_merged\"          # 合并权重目录\n",
    "TEST_FILE   = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH   = \"predictions_full.jsonl\"\n",
    "BATCH_START = 64           # 起步 batch；显存吃紧会自动减半\n",
    "MAX_NEW_TOK = 128         # 必要时调大 (诊疗报告 256)\n",
    "\n",
    "# -------- 环境微调 --------\n",
    "torch.backends.cuda.matmul.allow_tf32 = True       # 速度小提\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# -------- 模型 & tokenizer --------\n",
    "tok  = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side, tok.pad_token = \"left\", tok.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "# -------- 数据集按长度排序，减少 padding --------\n",
    "ds = load_dataset(\"json\", data_files={\"test\": TEST_FILE})[\"test\"]\n",
    "sorted_idx = sorted(range(len(ds)), key=lambda i: len(ds[i][\"instruction\"]) + len(ds[i][\"input\"]))\n",
    "ds = ds.select(sorted_idx)\n",
    "\n",
    "def to_list(start, bs):\n",
    "    \"\"\"把 Dataset 分片转成 List[dict]（确保索引合法）\"\"\"\n",
    "    sub = ds.select(range(start, min(start+bs, len(ds))))\n",
    "    return [sub[i] for i in range(len(sub))]\n",
    "\n",
    "def encode(batch):\n",
    "    prompts = [b[\"instruction\"] + \"\\n\" + b[\"input\"] for b in batch]\n",
    "    return tok(prompts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "def clean(ans: str) -> str:\n",
    "    ans = ans.strip()\n",
    "    ans = re.sub(r\"^(好的[,，]?\\s*|答[:：]?\\s*)\", \"\", ans)\n",
    "    return ans\n",
    "\n",
    "# -------- 推理主循环 --------\n",
    "curr_bs, i = BATCH_START, 0\n",
    "with open(SAVE_PATH, \"w\", encoding=\"utf8\") as fout, torch.no_grad():\n",
    "    pbar = tqdm.tqdm(total=len(ds), desc=\"Generating\")\n",
    "    while i < len(ds):\n",
    "        batch = to_list(i, curr_bs)\n",
    "        try:\n",
    "            toks  = encode(batch)\n",
    "            outs  = model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "            for sid, out in zip([b[\"id\"] for b in batch], outs):\n",
    "                pred = clean(tok.decode(out[toks[\"input_ids\"].shape[1]:], skip_special_tokens=True))\n",
    "                fout.write(json.dumps({\"id\": sid, \"prediction\": pred}, ensure_ascii=False) + \"\\n\")\n",
    "            i += curr_bs\n",
    "            pbar.update(curr_bs)\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "                curr_bs //= 2\n",
    "                if curr_bs == 0:\n",
    "                    raise RuntimeError(\"显存仍不足，已降至 batch=1 仍 OOM\") from e\n",
    "                print(f\"⚠️  OOM → batch_size 调至 {curr_bs}\")\n",
    "            else:\n",
    "                raise e\n",
    "    pbar.close()\n",
    "\n",
    "print(f\"✅ 预测完成 → {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, gc, tqdm, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_DIR  = \"qwen05_promptcblue_merged\"\n",
    "TEST_FILE  = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH  = \"predictions_full.jsonl\"\n",
    "MAX_NEW_TOK = 128\n",
    "BATCH_INIT  = 64          # 起步 batch\n",
    "MIN_BATCH   = 1          # 不再往下减时的底线\n",
    "\n",
    "# ---------- tokenizer & model ----------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side, tok.pad_token = \"left\", tok.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR, torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "    trust_remote_code=True).eval()\n",
    "\n",
    "# ---------- 数据 ----------\n",
    "ds = load_dataset(\"json\", data_files={\"test\": TEST_FILE})[\"test\"]\n",
    "sorted_idx = sorted(range(len(ds)), key=lambda i: len(ds[i][\"instruction\"]) + len(ds[i][\"input\"]))\n",
    "ds = ds.select(sorted_idx)\n",
    "\n",
    "# ---------- 读取已完成 ID，跳过 ----------\n",
    "done_ids = set()\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    with open(SAVE_PATH, encoding=\"utf8\") as f:\n",
    "        for l in f:\n",
    "            done_ids.add(json.loads(l)[\"id\"])\n",
    "print(f\"已完成 {len(done_ids)} / {len(ds)} 条，继续生成…\")\n",
    "\n",
    "def encode(batch):\n",
    "    prompts = [b[\"instruction\"] + \"\\n\" + b[\"input\"] for b in batch]\n",
    "    return tok(prompts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "def clean(ans):\n",
    "    return re.sub(r\"^(好的[,，]?\\s*|答[:：]?\\s*)\", \"\", ans.strip())\n",
    "\n",
    "curr_bs = BATCH_INIT\n",
    "i = 0\n",
    "with open(SAVE_PATH, \"a\", encoding=\"utf8\") as fout, torch.no_grad():\n",
    "    pbar = tqdm.tqdm(total=len(ds) - len(done_ids), desc=\"Resume-Gen\")\n",
    "    while i < len(ds):\n",
    "        # 跳过已完成\n",
    "        if ds[i][\"id\"] in done_ids:\n",
    "            i += 1\n",
    "            continue\n",
    "        # 准备 batch（只拿未完成样本）\n",
    "        batch, j = [], i\n",
    "        while j < len(ds) and len(batch) < curr_bs:\n",
    "            if ds[j][\"id\"] not in done_ids:\n",
    "                batch.append(ds[j])\n",
    "            j += 1\n",
    "        try:\n",
    "            toks = encode(batch)\n",
    "            outs = model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "            for sid, out in zip([b[\"id\"] for b in batch], outs):\n",
    "                fout.write(json.dumps({\"id\": sid,\n",
    "                                       \"prediction\": clean(tok.decode(out[toks[\"input_ids\"].shape[1]:],\n",
    "                                                                      skip_special_tokens=True))},\n",
    "                                      ensure_ascii=False) + \"\\n\")\n",
    "                done_ids.add(sid)\n",
    "                pbar.update(1)\n",
    "            i = j\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "                curr_bs = max(MIN_BATCH, curr_bs // 2)   # 正确减半\n",
    "                print(f\"⚠️  OOM！batch_size 降到 {curr_bs}\")\n",
    "                if curr_bs == MIN_BATCH:\n",
    "                    print(\"仍然 OOM？考虑把 MAX_NEW_TOK 调低再跑。\")\n",
    "            else:\n",
    "                raise e\n",
    "    pbar.close()\n",
    "\n",
    "print(\"🎉 预测完成！文件已写入\", SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, subprocess, sys, os, tqdm\n",
    "\n",
    "TEST_FILE = \"./processed/test_converted.jsonl\"\n",
    "RAW_PRED  = \"predictions_full.jsonl\"\n",
    "FIX_PRED  = \"predictions_fixed.jsonl\"\n",
    "DEFAULT_ANSWER = \"无法确定\"          # 给缺失样本的占位答案，可自定义\n",
    "\n",
    "# 1️⃣ 读取已有预测\n",
    "pred_dict = {}\n",
    "with open(RAW_PRED, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        pred_dict[obj[\"id\"]] = obj[\"prediction\"]\n",
    "\n",
    "print(\"原预测条数:\", len(pred_dict))\n",
    "\n",
    "# 2️⃣ 遍历测试集，补缺并写新文件\n",
    "with open(TEST_FILE, encoding=\"utf8\") as fin, \\\n",
    "     open(FIX_PRED,  \"w\", encoding=\"utf8\") as fout:\n",
    "    for line in tqdm.tqdm(fin, desc=\"Writing fixed\"):\n",
    "        sample = json.loads(line)\n",
    "        sid = sample[\"id\"]\n",
    "        ans = pred_dict.get(sid, DEFAULT_ANSWER)\n",
    "        fout.write(json.dumps({\"id\": sid, \"prediction\": ans},\n",
    "                              ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"修补完成 → 新文件:\", FIX_PRED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#要评分了，我的回复是predictions_fixed，现在要和官方正确标准比较，拿到分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# ==== ✅ 第一步：加载合并模型和分词器 ====\n",
    "merged_model_path = \"qwen05_promptcblue_merged\"  # 你保存的合并模型目录\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791532e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== ✏️ 第二步：填写你的输入（模拟医生问诊场景） ====\n",
    "your_input = \"\"\"\n",
    "\"糖尿病的病因是啥\"\n",
    "\"\"\"\n",
    "\n",
    "outputs = model.generate(\n",
    "    **tokenizer(your_input, return_tensors=\"pt\").to(model.device),\n",
    "    max_new_tokens=64,\n",
    "    do_sample=False,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,       # 🔒 避免复读关键\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(\"🤖 医生回复：\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 加载原生 Qwen 模型（无LoRA）\n",
    "base_model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6eff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 输入 prompt\n",
    "your_input = \"\"\"你是医生，\n",
    "### 病人：讲一下糖尿病的病因？\n",
    "医生：\"\"\"\n",
    "\n",
    "# 生成响应\n",
    "inputs = tokenizer(your_input, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "for stop_word in [\"患者：\", \"病人：\", \"Human:\", \"\\n\\n\"]:\n",
    "    if stop_word in response:\n",
    "        response = response.split(stop_word)[0]\n",
    "print(\"🧠 原生 Qwen 回复：\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# === 1. 加载合并后的 Qwen 模型 ===\n",
    "merged_model_path = \"qwen05_promptcblue_merged\"  # 修改为你保存模型的位置\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# === 2. 定义 PromptCBLUE 多任务测试输入 ===\n",
    "prompts = [\n",
    "    (\"CMeEE-V2\", \"请识别下面句子中的医学实体及类型。\\n\\n句子：患者出现剧烈咳嗽，面色苍白，伴随头晕和心悸。\"),\n",
    "    (\"CMeIE\", \"请抽取句子中的医学关系三元组。\\n\\n句子：心力衰竭可使用伊伐布雷治疗。\"),\n",
    "    (\"CHIP-CDN\", \"请将下面句子中提到的疾病或症状进行标准化。\\n\\n句子：患者疑似十二指肠交界性肿瘤及管状腺瘤。\"),\n",
    "    (\"CHIP-CDEE\", \"请抽取下面句子中的医学事件信息（主体词、修饰词、解剖部位等）。\\n\\n句子：患者腹痛、腹胀、恶心，伴有发热和头昏。\"),\n",
    "    (\"IMCS-V2-NER\", \"请标注以下句子中的医学实体及类型。\\n\\n句子：血常规提示白细胞升高，考虑病毒感染。\"),\n",
    "    (\"CHIP-MDCFNPC\", \"请判断下面描述中患者可能患有哪些疾病。\\n\\n描述：患者最近出现腹泻、水样便、肛门疼痛。\"),\n",
    "    (\"CHIP-STS\", \"判断下面两句话是否语义相似。\\n\\n句1：我最近咳嗽得厉害。\\n句2：我老是咳嗽。\"),\n",
    "    (\"KUAKE-QIC\", \"请判断下面的问题属于哪一类。\\n\\n问题：请问尿蛋白1+严重吗？\"),\n",
    "    (\"MedDG\", \"医生你好，我肚子疼。你觉得什么原因？\"),\n",
    "    (\"IMCS-V2-MRG\", \"请生成主诉、现病史、诊断和建议：\\n\\n描述：小孩腹泻两天，大便次数增多。\")\n",
    "]\n",
    "\n",
    "# === 3. 批量推理并展示结果 ===\n",
    "for task_name, prompt in prompts:\n",
    "    print(f\"=== [{task_name}] ===\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True, temperature=0.7,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    print(f\"📝 Prompt:\\n{prompt}\")\n",
    "    print(f\"🤖 模型回复:\\n{answer}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea73cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822f287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0789c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ab380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "raw_path = \"./processed/train_converted.jsonl\"\n",
    "filtered_path = \"./processed/train_top_task.jsonl\"\n",
    "\n",
    "# 1) 统计每种 instruction 出现次数\n",
    "instr_counter = Counter()\n",
    "samples_by_instr = defaultdict(list)\n",
    "\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        sample = json.loads(line)\n",
    "        instr = sample.get(\"instruction\", \"\").strip()\n",
    "        instr_counter[instr] += 1\n",
    "        samples_by_instr[instr].append(sample)\n",
    "\n",
    "# 2) 找到出现次数最多的 instruction\n",
    "top_instr, top_count = instr_counter.most_common(1)[0]\n",
    "top_samples = samples_by_instr[top_instr]\n",
    "\n",
    "print(f\"最常见 instruction:\\n{top_instr}\\n出现次数: {top_count}\")\n",
    "\n",
    "# 3) 将对应样本写入新 jsonl\n",
    "with open(filtered_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in top_samples:\n",
    "        f.write(json.dumps(s, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\n已将 {len(top_samples)} 条样本保存到 {filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 代码 Cell：从 dev_converted.jsonl 中提取指定任务并保存为 dev_top_task.jsonl\n",
    "input_file = './processed/dev_converted.jsonl'\n",
    "output_file = './processed/dev_top_task.jsonl'\n",
    "\n",
    "count = 0\n",
    "with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', encoding='utf-8') as fout:\n",
    "    for line in fin:\n",
    "        obj = json.loads(line)\n",
    "        if obj.get('instruction', '').startswith(\n",
    "            \"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\"\n",
    "        ):\n",
    "            fout.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Filtered {count} records into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2abccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LoRA fine-tune Qwen-0.5B with BF16, real-time loss plotting, CSV logging, and save-on-terminate ===\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# ─── 0) Setup ────────────────────────────────────────────────────────────────\n",
    "output_dir = \"lora_ckpt\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# ─── 1) Prepare Data ─────────────────────────────────────────────────────────\n",
    "def concat(example):\n",
    "    example[\"text\"] = example[\"instruction\"] + \"\\n\" + example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "    return example\n",
    "\n",
    "raw_ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"./processed/train_top_task.jsonl\",\n",
    "        \"validation\": \"./processed/dev_top_task.jsonl\"\n",
    "    }\n",
    ").map(concat)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=1024)\n",
    "\n",
    "tok_ds = raw_ds.map(tok_fn, batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# ─── 2) LoRA Adapter ─────────────────────────────────────────────────────────\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# ─── 3) Callback for Loss Logging & Plotting ─────────────────────────────────\n",
    "class LossCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        # Prepare CSV\n",
    "        self.csv_file = open(csv_path, 'w', newline='', encoding='utf-8')\n",
    "        self.csv_writer = csv.writer(self.csv_file)\n",
    "        self.csv_writer.writerow(['step', 'loss'])\n",
    "        # Prepare plot\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.line, = self.ax.plot([], [], lw=2)\n",
    "        self.ax.set_xlabel('Step')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.set_title('Training Loss')\n",
    "        self.steps, self.losses = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            step = state.global_step\n",
    "            loss = logs[\"loss\"]\n",
    "            self.steps.append(step)\n",
    "            self.losses.append(loss)\n",
    "            # write to CSV\n",
    "            self.csv_writer.writerow([step, loss])\n",
    "            self.csv_file.flush()\n",
    "            # update plot\n",
    "            self.line.set_data(self.steps, self.losses)\n",
    "            self.ax.relim()\n",
    "            self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw()\n",
    "            self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        self.csv_file.close()\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "loss_cb = LossCallback(csv_path=os.path.join(output_dir, \"loss.csv\"))\n",
    "\n",
    "# ─── 4) Training Arguments ───────────────────────────────────────────────────\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"adamw_torch_fused\"\n",
    ")\n",
    "\n",
    "# ─── 5) Trainer Init ─────────────────────────────────────────────────────────\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[loss_cb]\n",
    ")\n",
    "\n",
    "# ─── 6) Train with Interrupt Handling ────────────────────────────────────────\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"⚠️ Training interrupted. Saving current adapter and tokenizer...\")\n",
    "    trainer.save_model(os.path.join(output_dir, \"interrupted\"))\n",
    "    tokenizer.save_pretrained(os.path.join(output_dir, \"interrupted\"))\n",
    "finally:\n",
    "    print(\"✅ Training finished. Artifacts and loss logs are in:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d70661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c48b6808864469a876dec0acf0a7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:693: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9107, 'grad_norm': 1.71875, 'learning_rate': 0.00019786324786324788, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd99204e76054680b86c34157f069228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.735177516937256, 'eval_runtime': 187.3612, 'eval_samples_per_second': 4.27, 'eval_steps_per_second': 0.534, 'epoch': 0.03}\n",
      "{'loss': 1.8781, 'grad_norm': 2.25, 'learning_rate': 0.00019572649572649573, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de87d66066f4c9b8364b1c27507ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5323009490966797, 'eval_runtime': 186.7719, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.06}\n",
      "{'loss': 1.2013, 'grad_norm': 1.1640625, 'learning_rate': 0.0001935897435897436, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc16465ea5347cc887f29b265ec75ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.538970708847046, 'eval_runtime': 186.5812, 'eval_samples_per_second': 4.288, 'eval_steps_per_second': 0.536, 'epoch': 0.1}\n",
      "{'loss': 0.9408, 'grad_norm': 1.2578125, 'learning_rate': 0.00019145299145299148, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07527ee3c0ae4dc8a647cb8de0f4d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5759494304656982, 'eval_runtime': 186.7406, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 0.13}\n",
      "{'loss': 0.9613, 'grad_norm': 0.8203125, 'learning_rate': 0.00018931623931623933, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d60bc8830453294c4e6be65295507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6332669258117676, 'eval_runtime': 186.6771, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.16}\n",
      "{'loss': 0.8357, 'grad_norm': 0.75, 'learning_rate': 0.0001871794871794872, 'epoch': 0.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09f3a7d9934447fb0d90711966c2084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6640784740448, 'eval_runtime': 186.8481, 'eval_samples_per_second': 4.282, 'eval_steps_per_second': 0.535, 'epoch': 0.19}\n",
      "{'loss': 0.898, 'grad_norm': 0.921875, 'learning_rate': 0.00018504273504273505, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950df323064e42b4a2b1d34a81208944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.705317497253418, 'eval_runtime': 186.2823, 'eval_samples_per_second': 4.295, 'eval_steps_per_second': 0.537, 'epoch': 0.22}\n",
      "{'loss': 0.8569, 'grad_norm': 0.70703125, 'learning_rate': 0.00018290598290598292, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950255f71274439db42b60e34e2d3940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7448487281799316, 'eval_runtime': 186.6816, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.26}\n",
      "{'loss': 0.8168, 'grad_norm': 0.68359375, 'learning_rate': 0.00018076923076923077, 'epoch': 0.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096ecab4706b4c06bbab5c81ede9421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.687802791595459, 'eval_runtime': 186.6158, 'eval_samples_per_second': 4.287, 'eval_steps_per_second': 0.536, 'epoch': 0.29}\n",
      "{'loss': 0.8639, 'grad_norm': 0.62109375, 'learning_rate': 0.00017863247863247864, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1051762ef84ea49219e6168d011fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7188711166381836, 'eval_runtime': 186.5305, 'eval_samples_per_second': 4.289, 'eval_steps_per_second': 0.536, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8479, 'grad_norm': 0.53515625, 'learning_rate': 0.0001764957264957265, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598125594eff442394665f473058f2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.735438346862793, 'eval_runtime': 186.7905, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.35}\n",
      "{'loss': 0.8449, 'grad_norm': 0.5703125, 'learning_rate': 0.00017435897435897436, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0a5c97083f4efbbc6a3f7db4bfaf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7648589611053467, 'eval_runtime': 186.744, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 0.38}\n",
      "{'loss': 0.8207, 'grad_norm': 0.61328125, 'learning_rate': 0.00017222222222222224, 'epoch': 0.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dd7e6044854d939ae53b2f82577204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7146999835968018, 'eval_runtime': 186.8528, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 0.535, 'epoch': 0.42}\n",
      "{'loss': 0.7931, 'grad_norm': 0.62109375, 'learning_rate': 0.00017008547008547008, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1baf62eb9446cf97a57d5f18969c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7718944549560547, 'eval_runtime': 186.6242, 'eval_samples_per_second': 4.287, 'eval_steps_per_second': 0.536, 'epoch': 0.45}\n",
      "{'loss': 0.7273, 'grad_norm': 0.58984375, 'learning_rate': 0.00016794871794871796, 'epoch': 0.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05753440b4274eddbd30b29b7fc689ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7787740230560303, 'eval_runtime': 186.775, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8334, 'grad_norm': 0.56640625, 'learning_rate': 0.00016581196581196583, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aba03219024f8688c7131463a5fb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.773144483566284, 'eval_runtime': 186.4368, 'eval_samples_per_second': 4.291, 'eval_steps_per_second': 0.536, 'epoch': 0.51}\n",
      "{'loss': 0.7739, 'grad_norm': 0.44140625, 'learning_rate': 0.00016367521367521368, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd567fe37d0a420cb34243afb4428e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7180967330932617, 'eval_runtime': 186.7085, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.54}\n",
      "{'loss': 0.8224, 'grad_norm': 0.451171875, 'learning_rate': 0.00016153846153846155, 'epoch': 0.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f947a930f46e0b3747c0ba323e2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7706716060638428, 'eval_runtime': 186.3628, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.58}\n",
      "{'loss': 0.8268, 'grad_norm': 0.5078125, 'learning_rate': 0.00015940170940170943, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a3bb0dcf0741bba4e35b7efa045100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8255133628845215, 'eval_runtime': 186.4132, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.536, 'epoch': 0.61}\n",
      "{'loss': 0.8068, 'grad_norm': 0.5703125, 'learning_rate': 0.00015726495726495727, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c8e047fb0b46ecb6bb050d0d1b841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766544818878174, 'eval_runtime': 186.7523, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8159, 'grad_norm': 0.50390625, 'learning_rate': 0.00015512820512820515, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72447090720245b28159b9dc04a20ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.761665105819702, 'eval_runtime': 186.6988, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.67}\n",
      "{'loss': 0.7404, 'grad_norm': 0.53125, 'learning_rate': 0.000152991452991453, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb8df13673410784fe29ab41c89ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7524895668029785, 'eval_runtime': 186.7093, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.7}\n",
      "{'loss': 0.7716, 'grad_norm': 0.49609375, 'learning_rate': 0.00015085470085470087, 'epoch': 0.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64af5b9d73024f44a8b74317b5e01a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.782177448272705, 'eval_runtime': 186.6705, 'eval_samples_per_second': 4.286, 'eval_steps_per_second': 0.536, 'epoch': 0.74}\n",
      "{'loss': 0.7793, 'grad_norm': 0.59375, 'learning_rate': 0.00014871794871794872, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5d3efb2ee4ec5986bfb143487e0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.758836030960083, 'eval_runtime': 186.481, 'eval_samples_per_second': 4.29, 'eval_steps_per_second': 0.536, 'epoch': 0.77}\n",
      "{'loss': 0.8199, 'grad_norm': 0.48046875, 'learning_rate': 0.0001465811965811966, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eb743b6e1a46c0859b7baf155b7424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7495827674865723, 'eval_runtime': 186.7246, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7212, 'grad_norm': 0.490234375, 'learning_rate': 0.00014444444444444444, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62ab155766241ac8f8ffc1bbacdd116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7804272174835205, 'eval_runtime': 186.3579, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.83}\n",
      "{'loss': 0.7921, 'grad_norm': 0.482421875, 'learning_rate': 0.0001423076923076923, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16c928a67cb4c8e9562605a176c5793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.738548994064331, 'eval_runtime': 186.6649, 'eval_samples_per_second': 4.286, 'eval_steps_per_second': 0.536, 'epoch': 0.86}\n",
      "{'loss': 0.7646, 'grad_norm': 0.578125, 'learning_rate': 0.00014017094017094016, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e12beea55364e03ae3f7f39e8b2413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.774688482284546, 'eval_runtime': 186.7072, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.9}\n",
      "{'loss': 0.7924, 'grad_norm': 0.51953125, 'learning_rate': 0.00013803418803418803, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176d6330ad584ad9b584da6dfd49af6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7493133544921875, 'eval_runtime': 186.8936, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 0.535, 'epoch': 0.93}\n",
      "{'loss': 0.8439, 'grad_norm': 0.58203125, 'learning_rate': 0.0001358974358974359, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44e9ab6c0ec41b0b79bba20954b94d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.756263494491577, 'eval_runtime': 186.3636, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7677, 'grad_norm': 0.56640625, 'learning_rate': 0.00013376068376068375, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6a154447146de8ce09ae02b1e260e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.787390947341919, 'eval_runtime': 186.5364, 'eval_samples_per_second': 4.289, 'eval_steps_per_second': 0.536, 'epoch': 0.99}\n",
      "{'loss': 0.786, 'grad_norm': 0.47265625, 'learning_rate': 0.00013162393162393163, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6338a1f00e7d47e4b0a1df2fc47e5985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.762009859085083, 'eval_runtime': 186.4123, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.536, 'epoch': 1.02}\n",
      "{'loss': 0.7814, 'grad_norm': 0.55859375, 'learning_rate': 0.0001294871794871795, 'epoch': 1.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b837e435a852495886449ea20a74c9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.797741174697876, 'eval_runtime': 186.8079, 'eval_samples_per_second': 4.282, 'eval_steps_per_second': 0.535, 'epoch': 1.06}\n",
      "{'loss': 0.7769, 'grad_norm': 0.6953125, 'learning_rate': 0.00012735042735042735, 'epoch': 1.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b64a2545d5f47f3a9ae9d8ddb18f5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7983739376068115, 'eval_runtime': 186.7691, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.09}\n",
      "{'loss': 0.7823, 'grad_norm': 0.5859375, 'learning_rate': 0.00012521367521367522, 'epoch': 1.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812e49ca82a84a80829bb7f7053e7e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7533841133117676, 'eval_runtime': 186.6762, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7323, 'grad_norm': 0.515625, 'learning_rate': 0.0001230769230769231, 'epoch': 1.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aba69706d24a23bb11ad0d2696a55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.809715986251831, 'eval_runtime': 186.684, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.15}\n",
      "{'loss': 0.783, 'grad_norm': 0.5703125, 'learning_rate': 0.00012094017094017094, 'epoch': 1.18}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a571b9cb2745728c3b6c962133c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7659966945648193, 'eval_runtime': 186.7962, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.18}\n",
      "{'loss': 0.7701, 'grad_norm': 0.5, 'learning_rate': 0.0001188034188034188, 'epoch': 1.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d0cf1fab9e488a8c5cca31e11125b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7735137939453125, 'eval_runtime': 186.315, 'eval_samples_per_second': 4.294, 'eval_steps_per_second': 0.537, 'epoch': 1.22}\n",
      "{'loss': 0.7415, 'grad_norm': 0.578125, 'learning_rate': 0.00011666666666666668, 'epoch': 1.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f04588bd47740a1b6399f1923b6dc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8284246921539307, 'eval_runtime': 186.7429, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.25}\n",
      "{'loss': 0.7722, 'grad_norm': 0.5234375, 'learning_rate': 0.00011452991452991453, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74803f7b791846448361ca2acd8c6c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.817128896713257, 'eval_runtime': 186.3148, 'eval_samples_per_second': 4.294, 'eval_steps_per_second': 0.537, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7603, 'grad_norm': 0.484375, 'learning_rate': 0.0001123931623931624, 'epoch': 1.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36559c635ca4523b8a16397eefb540a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7782318592071533, 'eval_runtime': 186.3396, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.31}\n",
      "{'loss': 0.7973, 'grad_norm': 0.5625, 'learning_rate': 0.00011025641025641027, 'epoch': 1.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a021ff74069462d8446ba1476000f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7732274532318115, 'eval_runtime': 186.7442, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.34}\n",
      "{'loss': 0.7922, 'grad_norm': 0.5390625, 'learning_rate': 0.00010811965811965812, 'epoch': 1.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc23350c49c47d1af2266b4a59e4253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.788694143295288, 'eval_runtime': 186.7546, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.38}\n",
      "{'loss': 0.7502, 'grad_norm': 0.51953125, 'learning_rate': 0.000105982905982906, 'epoch': 1.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7618f2ea0d54470da2c63df5b2dbd809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.790432929992676, 'eval_runtime': 186.7569, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.41}\n",
      "{'loss': 0.8175, 'grad_norm': 0.515625, 'learning_rate': 0.00010384615384615386, 'epoch': 1.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c0e407458408ea67faec678819ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766448974609375, 'eval_runtime': 186.3294, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8247, 'grad_norm': 0.51953125, 'learning_rate': 0.0001017094017094017, 'epoch': 1.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efde6793f14545f2b8988aa07c6d80dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8005406856536865, 'eval_runtime': 186.7484, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.47}\n",
      "{'loss': 0.7404, 'grad_norm': 0.609375, 'learning_rate': 9.957264957264958e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031b3c1377f3498c9ae193a90a39e4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7964980602264404, 'eval_runtime': 186.7933, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.5}\n",
      "{'loss': 0.7168, 'grad_norm': 0.498046875, 'learning_rate': 9.743589743589744e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91459faf00b4035bb08e4097d61ff37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.799997568130493, 'eval_runtime': 186.4422, 'eval_samples_per_second': 4.291, 'eval_steps_per_second': 0.536, 'epoch': 1.54}\n",
      "{'loss': 0.7823, 'grad_norm': 0.49609375, 'learning_rate': 9.52991452991453e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951483e6f0646bf9469657b0bf132f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8017852306365967, 'eval_runtime': 186.7516, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.57}\n",
      "{'loss': 0.7768, 'grad_norm': 0.5859375, 'learning_rate': 9.316239316239317e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c3683c5a724dfdaed4ff9fcfffbbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8386521339416504, 'eval_runtime': 186.7496, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7936, 'grad_norm': 0.5234375, 'learning_rate': 9.102564102564103e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5bbc12e8449de9f511249a5bdb6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.810772180557251, 'eval_runtime': 186.7136, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.63}\n",
      "{'loss': 0.7243, 'grad_norm': 0.54296875, 'learning_rate': 8.888888888888889e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279a531fae144f2b98830b4935c6d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8049535751342773, 'eval_runtime': 186.7393, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 1.66}\n",
      "{'loss': 0.7819, 'grad_norm': 0.498046875, 'learning_rate': 8.675213675213675e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6571deb9fc4c4dc0aabee12ee62b2750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.789511203765869, 'eval_runtime': 186.786, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.7}\n",
      "{'loss': 0.7916, 'grad_norm': 0.578125, 'learning_rate': 8.461538461538461e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7179b6ae3b74488b86f7d5671df314bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.773860454559326, 'eval_runtime': 186.7738, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.73}\n",
      "{'loss': 0.8004, 'grad_norm': 0.5625, 'learning_rate': 8.247863247863247e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28ac670243b407999935b068c1d09c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7844290733337402, 'eval_runtime': 186.7756, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8128, 'grad_norm': 0.54296875, 'learning_rate': 8.034188034188035e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d2d3ec799e4266a96eb1f8b84796da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8049683570861816, 'eval_runtime': 186.7596, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.79}\n",
      "{'loss': 0.7574, 'grad_norm': 0.55078125, 'learning_rate': 7.820512820512821e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad7ada512064c21967ec7d888f503a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.806752920150757, 'eval_runtime': 186.7021, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.82}\n",
      "{'loss': 0.7963, 'grad_norm': 0.640625, 'learning_rate': 7.606837606837607e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e224eae1fa471eb62191d91550a326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8106603622436523, 'eval_runtime': 186.3376, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.86}\n",
      "{'loss': 0.6968, 'grad_norm': 0.5078125, 'learning_rate': 7.393162393162394e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4db7ce622c4908bf7c4f3eef792372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.807821273803711, 'eval_runtime': 186.711, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.89}\n",
      "{'loss': 0.7693, 'grad_norm': 0.52734375, 'learning_rate': 7.17948717948718e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18eaea565c4498595702396f80a2390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7869362831115723, 'eval_runtime': 186.8017, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7566, 'grad_norm': 0.5234375, 'learning_rate': 6.965811965811965e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dbd282172741db9e3021cb19812f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.78584361076355, 'eval_runtime': 186.3813, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.537, 'epoch': 1.95}\n",
      "{'loss': 0.7394, 'grad_norm': 0.5, 'learning_rate': 6.752136752136753e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b11a01376e744038824db46a6e5fbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7991693019866943, 'eval_runtime': 186.5705, 'eval_samples_per_second': 4.288, 'eval_steps_per_second': 0.536, 'epoch': 1.98}\n",
      "{'loss': 0.779, 'grad_norm': 0.53125, 'learning_rate': 6.538461538461539e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e51300325bb47a8ac4e2eb37a4716f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.801422119140625, 'eval_runtime': 186.7008, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 2.02}\n",
      "{'loss': 0.7889, 'grad_norm': 0.53515625, 'learning_rate': 6.324786324786325e-05, 'epoch': 2.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3affd2446224d27802363a2f2d002fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.791327476501465, 'eval_runtime': 186.7566, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 2.05}\n",
      "{'loss': 0.7867, 'grad_norm': 0.5625, 'learning_rate': 6.111111111111112e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20329fdc30e4bd79740a263f1c6fe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8012540340423584, 'eval_runtime': 191.3033, 'eval_samples_per_second': 4.182, 'eval_steps_per_second': 0.523, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7471, 'grad_norm': 0.52734375, 'learning_rate': 5.897435897435898e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b30ceebfb3c4193a2c12bca9ee63bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.817230224609375, 'eval_runtime': 196.612, 'eval_samples_per_second': 4.069, 'eval_steps_per_second': 0.509, 'epoch': 2.11}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m\n\u001b[0;32m    111\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    112\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    113\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[loss_cb]\n\u001b[0;32m    118\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# 7) 启动训练\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2209\u001b[0m ):\n\u001b[0;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\accelerate\\accelerator.py:2013\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2013\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 更新：每隔 step 记录 eval loss（更小间隔），并实时画图 & 存 CSV ===\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import os, csv, matplotlib.pyplot as plt\n",
    "\n",
    "# 0) 输出目录\n",
    "output_dir = \"lora_ckpt2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1) 加载模型与 tokenizer\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2) 数据处理（略，保持与之前相同）\n",
    "def concat(ex): ex[\"text\"] = ex[\"instruction\"]+\"\\n\"+ex[\"input\"]+\"\\n\"+ex[\"output\"]; return ex\n",
    "\n",
    "raw_ds = load_dataset(\"json\",\n",
    "    data_files={\"train\":\"./processed/train_top_task.jsonl\",\n",
    "                \"validation\":\"./processed/dev_top_task.jsonl\"}\n",
    ").map(concat)\n",
    "\n",
    "tok_ds = raw_ds.map(lambda b: tokenizer(b[\"text\"], truncation=True, max_length=1024),\n",
    "                   batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# 3) 插入 LoRA\n",
    "lora_cfg = LoraConfig(r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# 4) Callback：同时记录 train/eval loss\n",
    "class LossCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        # 打开 CSV\n",
    "        self.csv = open(csv_path, 'w', newline='', encoding='utf-8')\n",
    "        self.writer = csv.writer(self.csv)\n",
    "        self.writer.writerow(['step','type','loss'])\n",
    "        # 画布\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.line_t, = self.ax.plot([], [], label=\"train\")\n",
    "        self.line_v, = self.ax.plot([], [], label=\"eval\")\n",
    "        self.ax.set_xlabel(\"Step\"); self.ax.set_ylabel(\"Loss\")\n",
    "        self.ax.legend()\n",
    "        self.st_t, self.ls_t = [], []\n",
    "        self.st_v, self.ls_v = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kw):\n",
    "        if logs and \"loss\" in logs:\n",
    "            step, loss = state.global_step, logs[\"loss\"]\n",
    "            self.st_t.append(step); self.ls_t.append(loss)\n",
    "            self.writer.writerow([step, \"train\", loss]); self.csv.flush()\n",
    "            self.line_t.set_data(self.st_t, self.ls_t)\n",
    "            self.ax.relim(); self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw(); self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kw):\n",
    "        if metrics and \"eval_loss\" in metrics:\n",
    "            step, loss = state.global_step, metrics[\"eval_loss\"]\n",
    "            self.st_v.append(step); self.ls_v.append(loss)\n",
    "            self.writer.writerow([step, \"eval\", loss]); self.csv.flush()\n",
    "            self.line_v.set_data(self.st_v, self.ls_v)\n",
    "            self.ax.relim(); self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw(); self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_train_end(self, *args, **kw):\n",
    "        self.csv.close(); plt.ioff(); plt.show()\n",
    "\n",
    "loss_cb = LossCallback(os.path.join(output_dir, \"loss_log.csv\"))\n",
    "\n",
    "# 5) TrainingArguments：step 评估\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True, fp16=False,\n",
    "    logging_steps=10,              # 每 20 步记录 train loss\n",
    "    evaluation_strategy=\"steps\",  \n",
    "    eval_steps=10,                 # 每 50 步跑一次 validation\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    optim=\"adamw_torch_fused\"\n",
    ")\n",
    "\n",
    "# 6) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[loss_cb]\n",
    ")\n",
    "\n",
    "# 7) 启动训练\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dadcf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 201328128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 开始合并 LoRA 权重 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存到 qwen05_promptcblue_merged2\n",
      "🗣️ 推理结果: ____\n",
      "A. 急性支气管炎\n",
      "B. 肺部感染\n",
      "C. 支气管肺炎\n",
      "D. 咳嗽变异性哮喘\n",
      "答案:\n",
      "\n",
      "B\n",
      "\n",
      "关于胸腔积液的描述，下列哪项是错误的：\n",
      "A. 由于淋巴细胞减少\n"
     ]
    }
   ],
   "source": [
    "# === 合并 LoRA + 基座权重，得到可独立推理模型 ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch, os, shutil\n",
    "\n",
    "# 1) 路径配置\n",
    "base_model_id   = \"Qwen/Qwen2.5-0.5B-Instruct\"   # 原始基座\n",
    "lora_adapter_dir = \"lora_ckpt2/checkpoint-650\"             # 训练完的 LoRA 目录\n",
    "merged_dir       = \"qwen05_promptcblue_merged2\"   # 要保存的新目录\n",
    "\n",
    "# 2) 加载基座 & LoRA\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, lora_adapter_dir)\n",
    "print(\"🔄 开始合并 LoRA 权重 …\")\n",
    "model = model.merge_and_unload()   # ⭐ 一步到位\n",
    "\n",
    "# 3) 保存（含 tokenizer）\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "print(f\"✅ 已保存到 {merged_dir}\")\n",
    "\n",
    "# 4) （可选）快速 sanity check 推理\n",
    "prompt = \"患者出现咳嗽、发热、呼吸困难，应考虑哪种最可能的初步诊断？\"\n",
    "ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"🗣️ 推理结果:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ 推理结果: 和血常规看看。\n",
      "症状阴阳性选项：没有患有该症状，患有该症状，无法根据上下文确定病人是否患有该症状\n",
      "当前对话中的症状及其阴阳性判断为：\n",
      "炎症：没有患有该症状\n",
      "肝功能：患有该症状\n",
      "血常规：患有该症状\n",
      "肝功能：\n"
     ]
    }
   ],
   "source": [
    "train1 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "找出当前对话中的症状，并判断阴阳性：\n",
    "对话历史：\n",
    "医生：奶奶\n",
    "医生：大便什么样的？有味吗？\n",
    "当前对话：\n",
    "患者：有大便一直有味味道有絮状物\"\"\"\n",
    "\n",
    "\n",
    "train2 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "找出当前对话中的症状，并判断阴阳性：\n",
    "对话历史：\n",
    "医生：宝宝咳嗽是白天严重还是夜间严重\n",
    "患者：白天\n",
    "当前对话：\n",
    "医生：有没有喘鸣急症状\"\"\"\n",
    "\n",
    "train3 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "找出当前对话中的症状，并判断阴阳性：\n",
    "对话历史：\n",
    "医生：最近头痛厉害吗？有没有呕吐？\n",
    "患者：偶尔头晕，有时候恶心\n",
    "当前对话：\n",
    "医生：呕吐的频率是多少？\"\"\"\n",
    "\n",
    "train4 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "找出当前对话中的症状，并判断阴阳性：\n",
    "对话历史：\n",
    "医生：眼睛发黄多久了？\n",
    "患者：大概两天\n",
    "当前对话：\n",
    "医生：有发炎吗？\"\"\"\n",
    "\n",
    "train5 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "找出当前对话中的症状，并判断阴阳性：\n",
    "对话历史：\n",
    "医生：他有没有炎症？\n",
    "患者：肝功能检查有点高\n",
    "当前对话：\n",
    "医生：建议查个肝功能\"\"\"\n",
    "\n",
    "dev1 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "识别以下对话中的症状，并判断其阴阳性：\n",
    "对话历史：\n",
    "医生：你现在咳嗽怎么样\n",
    "当前对话：\n",
    "患者：没有咳嗽了，发烧退了\"\"\"\n",
    "dev2 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "对话历史：\n",
    "医生：有没有呼吸困难或者喘不上气的情况？\n",
    "患者：没有，就是痰多一点\n",
    "当前对话：\n",
    "医生：那应该不是喘息问题\"\"\"\n",
    "dev3 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "请判断当前对话中提到的症状及其状态：\n",
    "对话历史：\n",
    "医生：有没有头晕或者呕吐？\n",
    "患者：最近头晕比较明显\n",
    "当前对话：\n",
    "医生：有没有吐过？\"\"\"\n",
    "dev4 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "请判断“炎症”是否存在：\n",
    "对话历史：\n",
    "医生：他之前有发炎史吗？\n",
    "患者：有过肝炎\n",
    "当前对话：\n",
    "医生：现在肝功能恢复了没有\"\"\"\n",
    "\n",
    "dev5 = \"\"\"根据给定内容，判断列出的临床发现实体是阳性、阴性、其他还是不标注。\n",
    "可选标签：没有患有该症状, 患有该症状, 无法根据上下文确定病人是否患有该症状\n",
    "请判断患者是否存在“喘息”：\n",
    "对话历史：\n",
    "医生：晚上睡觉会喘不上气吗？\n",
    "患者：会\n",
    "当前对话：\n",
    "医生：考虑有点哮喘的表现\"\"\"\n",
    "# for i in range(1, 6):\n",
    "#     for prefix in [\"train\", \"dev\"]:\n",
    "#         prompt = eval(f\"{prefix}{i}\")\n",
    "#         ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#         out = model.generate(**ids, max_new_tokens=64)\n",
    "#         print(f\"\\n🧪 {prefix}{i} 推理结果:\\n\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n",
    "\n",
    "ids = tokenizer(train5, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"🗣️ 推理结果:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c624675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 [原始模型] train1 推理结果：\n",
      "\n",
      "\n",
      "临床发现：有大便一直有味味道有絮状物（阳） 根据给出的信息，\"有大便一直有味味道有絮状物\" 这个临床发现实体是阳性。因此，最终答案为阳性。\n",
      "\n",
      "🧪 [原始模型] dev1 推理结果：\n",
      "，但是还流鼻涕\n",
      "\n",
      "症状：发热\n",
      "阳性和阴性：发热\n",
      "阴阳性：阳性和阴性\n",
      "未标注：无\n",
      "（医生）: “你最近有没有感冒？”（患者）: “没有。”（医生）: \"那你能说一下你的症状吗？\"（患者\n",
      "\n",
      "🧪 [原始模型] train2 推理结果：\n",
      "？\n",
      "患者：无\n",
      "\n",
      "临床发现实体：其他\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：阴性\n",
      "临床发现实体：\n",
      "\n",
      "🧪 [原始模型] dev2 推理结果：\n",
      "，可能是感冒了\n",
      "患者：嗯\n",
      "\n",
      "临床发现：其他\n",
      "\n",
      "答案：其他\n",
      "\n",
      "医生：请问您最近有过咳嗽吗？如果有的话，请描述一下。\n",
      "患者：没有，就是偶尔咳几声。\n",
      "\n",
      "临床发现：其他\n",
      "\n",
      "答案：其他\n",
      "\n",
      "医生：那应该是感冒引起的咳嗽，可以吃点\n",
      "\n",
      "🧪 [原始模型] train3 推理结果：\n",
      "今天呕吐了几次？\n",
      "患者：今天早上吐了两次。今天下午又吐了一次。\n",
      "[沉默]  \n",
      "医生：你是不是吃多了？\n",
      "患者：没吃太多，只是吃了点食物。\n",
      "[沉默]\n",
      "医生：这是怎么回事啊？我问过你了。\n",
      "患者：我昨天晚上喝了半\n",
      "\n",
      "🧪 [原始模型] dev3 推理结果：\n",
      " \n",
      "患者：没\n",
      "\n",
      "当前讨论话题：无\n",
      "当前描述病情：头晕恶心\n",
      "目前可用诊断方法：头颅CT，胃镜检查\n",
      "目前可用药物治疗：止吐药\n",
      "可以推测出的诊断：眩晕症\n",
      "可能的病因：高血压\n",
      "可能的诱因：劳累\n",
      "可能\n",
      "\n",
      "🧪 [原始模型] train4 推理结果：\n",
      "眼睛发红吗？\n",
      "患者：没有\n",
      "\n",
      "临床发现：[“瞳孔散大”]\n",
      "\n",
      "临床发现：[“眼睑肿胀”]\n",
      "\n",
      "临床发现：[“角膜浑浊”] 其他\n",
      "\n",
      "阴性\n",
      "\n",
      "阴性\n",
      "\n",
      "阴性\n",
      "\n",
      "阴性\n",
      "\n",
      "阴性\n",
      "\n",
      "阴性\n",
      "\n",
      "\n",
      "\n",
      "🧪 [原始模型] dev4 推理结果：\n",
      "？\n",
      "患者：现在肝功能正常\n",
      "医生：那您是不是有发炎病史？\n",
      "患者：没有\n",
      "医生：那么您的炎症目前应该处于什么状态？（点头） \n",
      "医生：好。那您今天的情况怎么样？\n",
      "患者：我感觉还好。\n",
      "医生：好的，那您可以先回家休息几天\n",
      "\n",
      "🧪 [原始模型] train5 推理结果：\n",
      "\n",
      "医生：你有这个病吗？ \n",
      "患者：没\n",
      "\n",
      "阴性 根据给出的内容，\"肝功能检查有点高\" 是一个明确的症状描述。因此，根据 \"肝功能检查有点高\" 这一症状，我们可以判断出 \"阴性\"。\n",
      "\n",
      "最终答案：阴性。\n",
      "\n",
      "🧪 [原始模型] dev5 推理结果：\n",
      "，请问你有过接触过敏源吗？（患者点头）那你能说一下你最近有没有吃过什么对身体有害的食物吗？（患者点点头）我之前吃了海鲜。请问你有没有吃过海鲜？（患者点头）\n",
      "医生：海鲜可能会引起过敏反应。你的症状和之前的过敏史有关联\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# 1️⃣ 加载原始未微调模型\n",
    "base_model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2️⃣ 加载前面定义的 prompt（你已定义 train1~5 和 dev1~5）\n",
    "# 确保这些变量已经存在于当前环境中\n",
    "\n",
    "# 3️⃣ 批量生成并展示结果\n",
    "for i in range(1, 6):\n",
    "    for prefix in [\"train\", \"dev\"]:\n",
    "        prompt = eval(f\"{prefix}{i}\")\n",
    "        ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(**ids, max_new_tokens=64)\n",
    "        output = tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        print(f\"\\n🧪 [原始模型] {prefix}{i} 推理结果：\\n{output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a22f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================\n",
    "# # LoRA 微调 Qwen2-0.5B-Instruct —— 医学症状阴阳性判别\n",
    "# # 数据文件: /mnt/data/train_top_task.jsonl\n",
    "# # 训练结束后会把训练 loss 记录到 training_log.csv\n",
    "# # 并实时绘制 loss 曲线；支持 Ctrl-C/Interrupt 提前停止并保存权重\n",
    "# # ==============================================\n",
    "\n",
    "# import os, json, csv, time, math, torch, matplotlib.pyplot as plt\n",
    "# from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "# from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "# DATA_PATH = \"./processed/train_top_task.jsonl\"      # <-- 若路径不同请自行修改\n",
    "# MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "# OUTPUT_DIR = \"./qwen_lora_symptom\"\n",
    "# CSV_LOG = os.path.join(OUTPUT_DIR, \"training_log.csv\")\n",
    "\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# # 1) 加载数据集\n",
    "# dataset = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "\n",
    "# # 2) 简单 tokenize\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# def preprocess(example):\n",
    "#     prompt = f\"{example['instruction']}\\n\\n{example['input']}\\n\\n答案：\"\n",
    "#     example[\"prompt\"] = prompt\n",
    "#     example[\"labels\"] = example[\"output\"]\n",
    "#     return example\n",
    "\n",
    "# dataset = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
    "\n",
    "# def tokenize_func(example):\n",
    "#     model_input = tokenizer(example[\"prompt\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "#     label_ids = tokenizer(example[\"labels\"], truncation=True, max_length=128, padding=\"max_length\")[\"input_ids\"]\n",
    "#     model_input[\"labels\"] = label_ids\n",
    "#     return model_input\n",
    "\n",
    "# tokenized_ds = dataset.map(tokenize_func, batched=False)\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "# # 3) 加载模型并应用 LoRA\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\"\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 4) 定义训练参数\n",
    "# args = TrainingArguments(\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     learning_rate=2e-4,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=200,\n",
    "#     save_total_limit=2,\n",
    "#     fp16=True,\n",
    "#     report_to=[],\n",
    "# )\n",
    "\n",
    "# # 5) 自定义 Callback：记录 loss 到 CSV 并实时画图\n",
    "# from transformers import TrainerCallback\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "# class LossLoggerCallback(TrainerCallback):\n",
    "#     def __init__(self, csv_path):\n",
    "#         self.csv_path = csv_path\n",
    "#         # csv header\n",
    "#         if not os.path.exists(csv_path):\n",
    "#             with open(csv_path, \"w\", newline=\"\") as f:\n",
    "#                 writer = csv.writer(f); writer.writerow([\"step\", \"loss\"])\n",
    "#         self.losses = []\n",
    "\n",
    "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "#         if logs is None or \"loss\" not in logs:\n",
    "#             return\n",
    "#         step = state.global_step\n",
    "#         loss = logs[\"loss\"]\n",
    "#         self.losses.append((step, loss))\n",
    "#         # append to CSV\n",
    "#         with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "#             csv.writer(f).writerow([step, loss])\n",
    "\n",
    "#         # --- 实时绘图 ---\n",
    "#         clear_output(wait=True)\n",
    "#         steps, lossv = zip(*self.losses)\n",
    "#         plt.figure(figsize=(6,4))\n",
    "#         plt.plot(steps, lossv, label=\"train loss\")\n",
    "#         plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.title(\"Training Loss\")\n",
    "#         plt.legend(); plt.grid(True)\n",
    "#         display(plt.gcf())\n",
    "#         plt.close()\n",
    "\n",
    "# loss_cb = LossLoggerCallback(CSV_LOG)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=tokenized_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     callbacks=[loss_cb]\n",
    "# )\n",
    "\n",
    "# # 6) 训练带 try/except，支持 Ctrl-C 保存退出\n",
    "# try:\n",
    "#     trainer.train()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"⚠️ 手动停止训练，正在保存模型权重...\")\n",
    "#     trainer.save_model(os.path.join(OUTPUT_DIR, \"interrupted\"))\n",
    "#     print(\"✅ 权重已保存到 interrupted/ ，训练中断。\")\n",
    "#     raise\n",
    "\n",
    "# # 7) 训练完成后保存最终权重\n",
    "# trainer.save_model(os.path.join(OUTPUT_DIR, \"final\"))\n",
    "# print(\"🏁 训练完成，模型已保存到 final/ ，loss 记录在 training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0743d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, torch, matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM,\n",
    "                          TrainingArguments, Trainer,\n",
    "                          DataCollatorWithPadding, TrainerCallback)\n",
    "from peft import (prepare_model_for_kbit_training, LoraConfig,get_peft_model, TaskType)\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# ===== 路径 =====\n",
    "MODEL_NAME   = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "DATA_PATH    = \"./processed/train_top_task.jsonl\"\n",
    "OUTPUT_DIR   = \"./qwen_lora_symptom\"\n",
    "CSV_LOG      = os.path.join(OUTPUT_DIR, \"training_log.csv\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== 1. 数据 =====\n",
    "ds_raw = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "def preprocess(ex):\n",
    "    ex[\"prompt\"] = f'{ex[\"instruction\"]}\\n\\n{ex[\"input\"]}\\n\\n答案：'\n",
    "    ex[\"answer\"] = ex[\"output\"]\n",
    "    return ex\n",
    "\n",
    "ds = ds_raw.map(preprocess, remove_columns=ds_raw.column_names)\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    model_in = tokenizer(\n",
    "        ex[\"prompt\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    label_ids = tokenizer(\n",
    "        ex[\"answer\"], truncation=True, max_length=128, padding=\"max_length\"\n",
    "    )[\"input_ids\"]\n",
    "    # 把 padding 标成 -100 以屏蔽 loss\n",
    "    label_ids = [tok if tok != tokenizer.pad_token_id else -100\n",
    "                 for tok in label_ids]\n",
    "    model_in[\"labels\"] = label_ids\n",
    "    return model_in\n",
    "\n",
    "ds_tok = ds.map(tokenize_fn, batched=False)\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=None,\n",
    "                                   return_tensors=\"pt\")\n",
    "\n",
    "# ===== 2. 模型 & LoRA =====\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16,\n",
    "    trust_remote_code=True)\n",
    "base = prepare_model_for_kbit_training(base)\n",
    "\n",
    "lconf = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(base, lconf)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. 训练参数 =====\n",
    "args = TrainingArguments(\n",
    "    output_dir          = OUTPUT_DIR,\n",
    "    num_train_epochs    = 3,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    learning_rate       = 2e-4,\n",
    "    logging_steps       = 10,\n",
    "    save_steps          = 200,\n",
    "    save_total_limit    = 2,\n",
    "    fp16                = True,\n",
    "    report_to           = [],\n",
    "    label_names         = [\"labels\"],   # <- 告诉 Trainer 用 labels 字段\n",
    ")\n",
    "\n",
    "# ===== 4. Loss 记录 & 曲线 =====\n",
    "class LossPlotCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv = csv_path\n",
    "        if not os.path.exists(self.csv):\n",
    "            with open(self.csv, \"w\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([\"step\", \"loss\"])\n",
    "        self.buf = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kw):\n",
    "        if logs is None or \"loss\" not in logs:\n",
    "            return\n",
    "        step, loss = state.global_step, logs[\"loss\"]\n",
    "        self.buf.append((step, loss))\n",
    "        with open(self.csv, \"a\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow([step, loss])\n",
    "        # 实时曲线\n",
    "        clear_output(wait=True)\n",
    "        xs, ys = zip(*self.buf)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(xs, ys); plt.grid(); plt.xlabel(\"step\"); plt.ylabel(\"loss\")\n",
    "        plt.title(\"Training Loss\"); display(plt.gcf()); plt.close()\n",
    "\n",
    "loss_cb = LossPlotCallback(CSV_LOG)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    callbacks=[loss_cb],\n",
    ")\n",
    "\n",
    "# ===== 5. 训练（支持 Ctrl-C 保存权重） =====\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"⚠️ 手动停止，保存权重中 …\")\n",
    "    trainer.save_model(os.path.join(OUTPUT_DIR, \"interrupted\"))\n",
    "    print(\"✅ 已保存至 interrupted/\")\n",
    "    raise\n",
    "\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, \"final\"))\n",
    "print(\"🏁 训练完成！权重写入 final/ ，loss 记录在 training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d3187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "109a7257",
   "metadata": {},
   "source": [
    "Label conflicts: The same symptom received conflicting labels,\n",
    "     e.g., “咳嗽：患有该症状” and “咳嗽：没有患有该症状” in one output.\n",
    "\n",
    "Symptom duplication: Repetitive entries for the same phrase with no added meaning.\n",
    "     e.g.,“阴性”，“阴性”，“阴性”，“阴性”，“阴性”，“阴性”，“阴性”，“阳性”。\n",
    "\n",
    "Format drift: Outputs sometimes shifted into natural prose,\n",
    "     e.g., “患者头痛不明显，初步考虑为阳性状态。”\n",
    "\n",
    "Non-symptom inclusion: \n",
    "    Phrases like “治疗建议” or “吐的频率是多少” were misclassified as symptoms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          患者可能出现发烧和咳嗽，请结合临床判断。  \n",
    "          建议进行头颅CT检查以排除脑出血。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          患者烧得很明显，为阳性。\n",
    "          该症状考虑为阳性，患者表现突出。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen05_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
