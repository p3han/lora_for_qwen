{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè‡ªæ£€ï¼šPyTorch + CUDA\n",
    "import torch, platform, os, sys, subprocess, datetime\n",
    "print(f\"[æ—¶é—´] {datetime.datetime.now()}\")\n",
    "print(f\"[Python] {sys.version.split()[0]}  ({platform.platform()})\")\n",
    "print(f\"[Torch]  {torch.__version__}\")\n",
    "print(f\"[CUDA]   å¯ç”¨ = {torch.cuda.is_available()} | ç‰ˆæœ¬ = {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_properties(0)\n",
    "    print(f\"[GPU]    {gpu.name}  æ˜¾å­˜ {gpu.total_memory/1024**3:.1f} GB\")\n",
    "\n",
    "# ç®€å•å¼ é‡è¿ç®—ï¼ŒéªŒè¯ GPU èƒ½è·‘ FP16\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.randn(8_000_000, device=\"cuda\", dtype=torch.float16)\n",
    "    y = x * 2 + 1\n",
    "    print(\"Tensor OK â€¼ï¸  å‡å€¼:\", y.mean().item())\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æ£€æµ‹åˆ° GPUï¼Œæ£€æŸ¥æ˜¾å¡é©±åŠ¨ / CUDA Toolkit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch, os\n",
    "\n",
    "# å¦‚æœä½ ä¹‹å‰ `setx HF_HOME D:\\hf_cache`ï¼Œä¸‹é¢ä¸éœ€è¦é¢å¤–æŒ‡å®š cache_dirï¼›\n",
    "# å¦åˆ™æ‰‹åŠ¨åŠ  cache_dir=\"D:/hf_cache\"\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",         # è‡ªåŠ¨æŠŠ 0.5B ä¸¢åˆ° GPU 0\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "prompt = \"è¯·ç”¨ä¸€å¥è¯å‘Šè¯‰æˆ‘ PromptCBLUE æ•°æ®é›†æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "gen_ids = model.generate(**inputs, max_new_tokens=64, do_sample=False)\n",
    "print(tokenizer.decode(gen_ids[0, inputs['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LoRA fine-tune Qwen-0.5B with BF16 ===\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM,\n",
    "                          TrainingArguments, Trainer,\n",
    "                          DataCollatorForLanguageModeling)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch, os\n",
    "\n",
    "# 0) åŸºåº§æ¨¡å‹ï¼ˆä¸€æ¬¡å°±å¤Ÿï¼Œå¦‚æœä¸Šé¢å·²ç»åŠ è½½å°±å¤ç”¨ï¼‰\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,     # *** å…³é”®ï¼šç›´æ¥ç”¨ BF16 æƒé‡ ***\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 1) è¯»æ•°æ®å¹¶æ‹¼ Prompt\n",
    "def concat(example):\n",
    "    example[\"text\"] = example[\"instruction\"] + \"\\n\" + example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "    return example\n",
    "\n",
    "raw_ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\":\"./processed/train_top_task.jsonl\",\n",
    "        \"validation\":\"./processed/dev_converted.jsonl\"\n",
    "    }\n",
    ").map(concat)\n",
    "\n",
    "# 2) Tokenize -> ids\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=1024)\n",
    "tok_ds = raw_ds.map(tok_fn, batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# 3) LoRA é€‚é…å™¨\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16, target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# 4) è®­ç»ƒå‚æ•° â€”â€” ç”¨ bf16ï¼Œå…³é—­ fp16\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"lora_ckpt\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,                # â­ å¼€å¯ BF16\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"adamw_torch_fused\"  # PyTorch è‡ªå¸¦ fused AdamWï¼Œæ›´ç¨³\n",
    ")\n",
    "\n",
    "# 5) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# 6) ä¿å­˜é€‚é…å™¨\n",
    "trainer.save_model(\"lora_ckpt/final\")\n",
    "tokenizer.save_pretrained(\"lora_ckpt/final\")\n",
    "print(\"âœ… LoRA + BF16 è®­ç»ƒå®Œæˆï¼Œæƒé‡åœ¨ lora_ckpt/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === åˆå¹¶ LoRA + åŸºåº§æƒé‡ï¼Œå¾—åˆ°å¯ç‹¬ç«‹æ¨ç†æ¨¡å‹ ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch, os, shutil\n",
    "\n",
    "# 1) è·¯å¾„é…ç½®\n",
    "base_model_id   = \"Qwen/Qwen2.5-0.5B-Instruct\"   # åŸå§‹åŸºåº§\n",
    "lora_adapter_dir = \"lora_ckpt/final\"             # è®­ç»ƒå®Œçš„ LoRA ç›®å½•\n",
    "merged_dir       = \"qwen05_promptcblue_merged\"   # è¦ä¿å­˜çš„æ–°ç›®å½•\n",
    "\n",
    "# 2) åŠ è½½åŸºåº§ & LoRA\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, lora_adapter_dir)\n",
    "print(\"ğŸ”„ å¼€å§‹åˆå¹¶ LoRA æƒé‡ â€¦\")\n",
    "model = model.merge_and_unload()   # â­ ä¸€æ­¥åˆ°ä½\n",
    "\n",
    "# 3) ä¿å­˜ï¼ˆå« tokenizerï¼‰\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "print(f\"âœ… å·²ä¿å­˜åˆ° {merged_dir}\")\n",
    "\n",
    "# 4) ï¼ˆå¯é€‰ï¼‰å¿«é€Ÿ sanity check æ¨ç†\n",
    "prompt = \"æ‚£è€…å‡ºç°å’³å—½ã€å‘çƒ­ã€å‘¼å¸å›°éš¾ï¼Œåº”è€ƒè™‘å“ªç§æœ€å¯èƒ½çš„åˆæ­¥è¯Šæ–­ï¼Ÿ\"\n",
    "ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"ğŸ—£ï¸ æ¨ç†ç»“æœ:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# PromptCBLUE â€” SAFE å•æ¡æ¨ç†ï¼Œç»ä¸ä¼š OOM\n",
    "# ================================================\n",
    "import os, json, re, gc, tqdm, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_DIR  = \"qwen05_promptcblue_merged\"\n",
    "TEST_FILE  = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH  = \"predictions_full.jsonl\"\n",
    "MAX_NEW_TOK = 128\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side = \"left\"\n",
    "tok.pad_token = tok.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16,     # bf16 å ç”¨ä½ä¸”ç¨³å®š\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "with open(TEST_FILE, encoding=\"utf8\") as f_in, \\\n",
    "     open(SAVE_PATH, \"w\", encoding=\"utf8\") as f_out, \\\n",
    "     torch.no_grad():\n",
    "    \n",
    "    for line in tqdm.tqdm(f_in, total=sum(1 for _ in open(TEST_FILE, encoding=\"utf8\")), desc=\"Gen\"):\n",
    "        j = json.loads(line)\n",
    "        \n",
    "        prompt = j[\"instruction\"] + \"\\n\" + j[\"input\"]\n",
    "        toks   = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        out_ids= model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "        ans    = tok.decode(out_ids[0, toks[\"input_ids\"].shape[1]:],\n",
    "                            skip_special_tokens=True).strip()\n",
    "        ans    = re.sub(r\"^(å¥½çš„[,ï¼Œ]?\\s*|ç­”[:ï¼š]?\\s*)\", \"\", ans)  # å»å®¢å¥—å‰ç¼€\n",
    "\n",
    "        f_out.write(json.dumps({\"id\": j[\"id\"], \"prediction\": ans},\n",
    "                               ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # ç«‹å³é‡Šæ”¾æœ¬æ¡æ˜¾å­˜ï¼Œé˜²ç¢ç‰‡\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(f\"âœ… å…¨é‡é¢„æµ‹å·²å†™å…¥ {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3429ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PromptCBLUE é¢„æµ‹ â€” OOM-SAFE + GPU ååæœ€å¤§åŒ–  (batch=8â†’1)\n",
    "# ==========================================================\n",
    "import os, json, re, gc, tqdm, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# -------- åŸºæœ¬é…ç½® --------\n",
    "MODEL_DIR   = \"qwen05_promptcblue_merged\"          # åˆå¹¶æƒé‡ç›®å½•\n",
    "TEST_FILE   = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH   = \"predictions_full.jsonl\"\n",
    "BATCH_START = 64           # èµ·æ­¥ batchï¼›æ˜¾å­˜åƒç´§ä¼šè‡ªåŠ¨å‡åŠ\n",
    "MAX_NEW_TOK = 128         # å¿…è¦æ—¶è°ƒå¤§ (è¯Šç–—æŠ¥å‘Š 256)\n",
    "\n",
    "# -------- ç¯å¢ƒå¾®è°ƒ --------\n",
    "torch.backends.cuda.matmul.allow_tf32 = True       # é€Ÿåº¦å°æ\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# -------- æ¨¡å‹ & tokenizer --------\n",
    "tok  = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side, tok.pad_token = \"left\", tok.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "# -------- æ•°æ®é›†æŒ‰é•¿åº¦æ’åºï¼Œå‡å°‘ padding --------\n",
    "ds = load_dataset(\"json\", data_files={\"test\": TEST_FILE})[\"test\"]\n",
    "sorted_idx = sorted(range(len(ds)), key=lambda i: len(ds[i][\"instruction\"]) + len(ds[i][\"input\"]))\n",
    "ds = ds.select(sorted_idx)\n",
    "\n",
    "def to_list(start, bs):\n",
    "    \"\"\"æŠŠ Dataset åˆ†ç‰‡è½¬æˆ List[dict]ï¼ˆç¡®ä¿ç´¢å¼•åˆæ³•ï¼‰\"\"\"\n",
    "    sub = ds.select(range(start, min(start+bs, len(ds))))\n",
    "    return [sub[i] for i in range(len(sub))]\n",
    "\n",
    "def encode(batch):\n",
    "    prompts = [b[\"instruction\"] + \"\\n\" + b[\"input\"] for b in batch]\n",
    "    return tok(prompts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "def clean(ans: str) -> str:\n",
    "    ans = ans.strip()\n",
    "    ans = re.sub(r\"^(å¥½çš„[,ï¼Œ]?\\s*|ç­”[:ï¼š]?\\s*)\", \"\", ans)\n",
    "    return ans\n",
    "\n",
    "# -------- æ¨ç†ä¸»å¾ªç¯ --------\n",
    "curr_bs, i = BATCH_START, 0\n",
    "with open(SAVE_PATH, \"w\", encoding=\"utf8\") as fout, torch.no_grad():\n",
    "    pbar = tqdm.tqdm(total=len(ds), desc=\"Generating\")\n",
    "    while i < len(ds):\n",
    "        batch = to_list(i, curr_bs)\n",
    "        try:\n",
    "            toks  = encode(batch)\n",
    "            outs  = model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "            for sid, out in zip([b[\"id\"] for b in batch], outs):\n",
    "                pred = clean(tok.decode(out[toks[\"input_ids\"].shape[1]:], skip_special_tokens=True))\n",
    "                fout.write(json.dumps({\"id\": sid, \"prediction\": pred}, ensure_ascii=False) + \"\\n\")\n",
    "            i += curr_bs\n",
    "            pbar.update(curr_bs)\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "                curr_bs //= 2\n",
    "                if curr_bs == 0:\n",
    "                    raise RuntimeError(\"æ˜¾å­˜ä»ä¸è¶³ï¼Œå·²é™è‡³ batch=1 ä» OOM\") from e\n",
    "                print(f\"âš ï¸  OOM â†’ batch_size è°ƒè‡³ {curr_bs}\")\n",
    "            else:\n",
    "                raise e\n",
    "    pbar.close()\n",
    "\n",
    "print(f\"âœ… é¢„æµ‹å®Œæˆ â†’ {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, gc, tqdm, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_DIR  = \"qwen05_promptcblue_merged\"\n",
    "TEST_FILE  = \"./processed/test_converted.jsonl\"\n",
    "SAVE_PATH  = \"predictions_full.jsonl\"\n",
    "MAX_NEW_TOK = 128\n",
    "BATCH_INIT  = 64          # èµ·æ­¥ batch\n",
    "MIN_BATCH   = 1          # ä¸å†å¾€ä¸‹å‡æ—¶çš„åº•çº¿\n",
    "\n",
    "# ---------- tokenizer & model ----------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "tok.padding_side, tok.pad_token = \"left\", tok.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR, torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "    trust_remote_code=True).eval()\n",
    "\n",
    "# ---------- æ•°æ® ----------\n",
    "ds = load_dataset(\"json\", data_files={\"test\": TEST_FILE})[\"test\"]\n",
    "sorted_idx = sorted(range(len(ds)), key=lambda i: len(ds[i][\"instruction\"]) + len(ds[i][\"input\"]))\n",
    "ds = ds.select(sorted_idx)\n",
    "\n",
    "# ---------- è¯»å–å·²å®Œæˆ IDï¼Œè·³è¿‡ ----------\n",
    "done_ids = set()\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    with open(SAVE_PATH, encoding=\"utf8\") as f:\n",
    "        for l in f:\n",
    "            done_ids.add(json.loads(l)[\"id\"])\n",
    "print(f\"å·²å®Œæˆ {len(done_ids)} / {len(ds)} æ¡ï¼Œç»§ç»­ç”Ÿæˆâ€¦\")\n",
    "\n",
    "def encode(batch):\n",
    "    prompts = [b[\"instruction\"] + \"\\n\" + b[\"input\"] for b in batch]\n",
    "    return tok(prompts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "def clean(ans):\n",
    "    return re.sub(r\"^(å¥½çš„[,ï¼Œ]?\\s*|ç­”[:ï¼š]?\\s*)\", \"\", ans.strip())\n",
    "\n",
    "curr_bs = BATCH_INIT\n",
    "i = 0\n",
    "with open(SAVE_PATH, \"a\", encoding=\"utf8\") as fout, torch.no_grad():\n",
    "    pbar = tqdm.tqdm(total=len(ds) - len(done_ids), desc=\"Resume-Gen\")\n",
    "    while i < len(ds):\n",
    "        # è·³è¿‡å·²å®Œæˆ\n",
    "        if ds[i][\"id\"] in done_ids:\n",
    "            i += 1\n",
    "            continue\n",
    "        # å‡†å¤‡ batchï¼ˆåªæ‹¿æœªå®Œæˆæ ·æœ¬ï¼‰\n",
    "        batch, j = [], i\n",
    "        while j < len(ds) and len(batch) < curr_bs:\n",
    "            if ds[j][\"id\"] not in done_ids:\n",
    "                batch.append(ds[j])\n",
    "            j += 1\n",
    "        try:\n",
    "            toks = encode(batch)\n",
    "            outs = model.generate(**toks, max_new_tokens=MAX_NEW_TOK)\n",
    "            for sid, out in zip([b[\"id\"] for b in batch], outs):\n",
    "                fout.write(json.dumps({\"id\": sid,\n",
    "                                       \"prediction\": clean(tok.decode(out[toks[\"input_ids\"].shape[1]:],\n",
    "                                                                      skip_special_tokens=True))},\n",
    "                                      ensure_ascii=False) + \"\\n\")\n",
    "                done_ids.add(sid)\n",
    "                pbar.update(1)\n",
    "            i = j\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "                curr_bs = max(MIN_BATCH, curr_bs // 2)   # æ­£ç¡®å‡åŠ\n",
    "                print(f\"âš ï¸  OOMï¼batch_size é™åˆ° {curr_bs}\")\n",
    "                if curr_bs == MIN_BATCH:\n",
    "                    print(\"ä»ç„¶ OOMï¼Ÿè€ƒè™‘æŠŠ MAX_NEW_TOK è°ƒä½å†è·‘ã€‚\")\n",
    "            else:\n",
    "                raise e\n",
    "    pbar.close()\n",
    "\n",
    "print(\"ğŸ‰ é¢„æµ‹å®Œæˆï¼æ–‡ä»¶å·²å†™å…¥\", SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, subprocess, sys, os, tqdm\n",
    "\n",
    "TEST_FILE = \"./processed/test_converted.jsonl\"\n",
    "RAW_PRED  = \"predictions_full.jsonl\"\n",
    "FIX_PRED  = \"predictions_fixed.jsonl\"\n",
    "DEFAULT_ANSWER = \"æ— æ³•ç¡®å®š\"          # ç»™ç¼ºå¤±æ ·æœ¬çš„å ä½ç­”æ¡ˆï¼Œå¯è‡ªå®šä¹‰\n",
    "\n",
    "# 1ï¸âƒ£ è¯»å–å·²æœ‰é¢„æµ‹\n",
    "pred_dict = {}\n",
    "with open(RAW_PRED, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        pred_dict[obj[\"id\"]] = obj[\"prediction\"]\n",
    "\n",
    "print(\"åŸé¢„æµ‹æ¡æ•°:\", len(pred_dict))\n",
    "\n",
    "# 2ï¸âƒ£ éå†æµ‹è¯•é›†ï¼Œè¡¥ç¼ºå¹¶å†™æ–°æ–‡ä»¶\n",
    "with open(TEST_FILE, encoding=\"utf8\") as fin, \\\n",
    "     open(FIX_PRED,  \"w\", encoding=\"utf8\") as fout:\n",
    "    for line in tqdm.tqdm(fin, desc=\"Writing fixed\"):\n",
    "        sample = json.loads(line)\n",
    "        sid = sample[\"id\"]\n",
    "        ans = pred_dict.get(sid, DEFAULT_ANSWER)\n",
    "        fout.write(json.dumps({\"id\": sid, \"prediction\": ans},\n",
    "                              ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"ä¿®è¡¥å®Œæˆ â†’ æ–°æ–‡ä»¶:\", FIX_PRED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¦è¯„åˆ†äº†ï¼Œæˆ‘çš„å›å¤æ˜¯predictions_fixedï¼Œç°åœ¨è¦å’Œå®˜æ–¹æ­£ç¡®æ ‡å‡†æ¯”è¾ƒï¼Œæ‹¿åˆ°åˆ†æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# ==== âœ… ç¬¬ä¸€æ­¥ï¼šåŠ è½½åˆå¹¶æ¨¡å‹å’Œåˆ†è¯å™¨ ====\n",
    "merged_model_path = \"qwen05_promptcblue_merged\"  # ä½ ä¿å­˜çš„åˆå¹¶æ¨¡å‹ç›®å½•\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791532e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== âœï¸ ç¬¬äºŒæ­¥ï¼šå¡«å†™ä½ çš„è¾“å…¥ï¼ˆæ¨¡æ‹ŸåŒ»ç”Ÿé—®è¯Šåœºæ™¯ï¼‰ ====\n",
    "your_input = \"\"\"\n",
    "\"ç³–å°¿ç—…çš„ç—…å› æ˜¯å•¥\"\n",
    "\"\"\"\n",
    "\n",
    "outputs = model.generate(\n",
    "    **tokenizer(your_input, return_tensors=\"pt\").to(model.device),\n",
    "    max_new_tokens=64,\n",
    "    do_sample=False,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,       # ğŸ”’ é¿å…å¤è¯»å…³é”®\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(\"ğŸ¤– åŒ»ç”Ÿå›å¤ï¼š\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# åŠ è½½åŸç”Ÿ Qwen æ¨¡å‹ï¼ˆæ— LoRAï¼‰\n",
    "base_model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6eff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# è¾“å…¥ prompt\n",
    "your_input = \"\"\"ä½ æ˜¯åŒ»ç”Ÿï¼Œ\n",
    "### ç—…äººï¼šè®²ä¸€ä¸‹ç³–å°¿ç—…çš„ç—…å› ï¼Ÿ\n",
    "åŒ»ç”Ÿï¼š\"\"\"\n",
    "\n",
    "# ç”Ÿæˆå“åº”\n",
    "inputs = tokenizer(your_input, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "for stop_word in [\"æ‚£è€…ï¼š\", \"ç—…äººï¼š\", \"Human:\", \"\\n\\n\"]:\n",
    "    if stop_word in response:\n",
    "        response = response.split(stop_word)[0]\n",
    "print(\"ğŸ§  åŸç”Ÿ Qwen å›å¤ï¼š\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# === 1. åŠ è½½åˆå¹¶åçš„ Qwen æ¨¡å‹ ===\n",
    "merged_model_path = \"qwen05_promptcblue_merged\"  # ä¿®æ”¹ä¸ºä½ ä¿å­˜æ¨¡å‹çš„ä½ç½®\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# === 2. å®šä¹‰ PromptCBLUE å¤šä»»åŠ¡æµ‹è¯•è¾“å…¥ ===\n",
    "prompts = [\n",
    "    (\"CMeEE-V2\", \"è¯·è¯†åˆ«ä¸‹é¢å¥å­ä¸­çš„åŒ»å­¦å®ä½“åŠç±»å‹ã€‚\\n\\nå¥å­ï¼šæ‚£è€…å‡ºç°å‰§çƒˆå’³å—½ï¼Œé¢è‰²è‹ç™½ï¼Œä¼´éšå¤´æ™•å’Œå¿ƒæ‚¸ã€‚\"),\n",
    "    (\"CMeIE\", \"è¯·æŠ½å–å¥å­ä¸­çš„åŒ»å­¦å…³ç³»ä¸‰å…ƒç»„ã€‚\\n\\nå¥å­ï¼šå¿ƒåŠ›è¡°ç«­å¯ä½¿ç”¨ä¼Šä¼å¸ƒé›·æ²»ç–—ã€‚\"),\n",
    "    (\"CHIP-CDN\", \"è¯·å°†ä¸‹é¢å¥å­ä¸­æåˆ°çš„ç–¾ç—…æˆ–ç—‡çŠ¶è¿›è¡Œæ ‡å‡†åŒ–ã€‚\\n\\nå¥å­ï¼šæ‚£è€…ç–‘ä¼¼åäºŒæŒ‡è‚ äº¤ç•Œæ€§è‚¿ç˜¤åŠç®¡çŠ¶è…ºç˜¤ã€‚\"),\n",
    "    (\"CHIP-CDEE\", \"è¯·æŠ½å–ä¸‹é¢å¥å­ä¸­çš„åŒ»å­¦äº‹ä»¶ä¿¡æ¯ï¼ˆä¸»ä½“è¯ã€ä¿®é¥°è¯ã€è§£å‰–éƒ¨ä½ç­‰ï¼‰ã€‚\\n\\nå¥å­ï¼šæ‚£è€…è…¹ç—›ã€è…¹èƒ€ã€æ¶å¿ƒï¼Œä¼´æœ‰å‘çƒ­å’Œå¤´æ˜ã€‚\"),\n",
    "    (\"IMCS-V2-NER\", \"è¯·æ ‡æ³¨ä»¥ä¸‹å¥å­ä¸­çš„åŒ»å­¦å®ä½“åŠç±»å‹ã€‚\\n\\nå¥å­ï¼šè¡€å¸¸è§„æç¤ºç™½ç»†èƒå‡é«˜ï¼Œè€ƒè™‘ç—…æ¯’æ„ŸæŸ“ã€‚\"),\n",
    "    (\"CHIP-MDCFNPC\", \"è¯·åˆ¤æ–­ä¸‹é¢æè¿°ä¸­æ‚£è€…å¯èƒ½æ‚£æœ‰å“ªäº›ç–¾ç—…ã€‚\\n\\næè¿°ï¼šæ‚£è€…æœ€è¿‘å‡ºç°è…¹æ³»ã€æ°´æ ·ä¾¿ã€è‚›é—¨ç–¼ç—›ã€‚\"),\n",
    "    (\"CHIP-STS\", \"åˆ¤æ–­ä¸‹é¢ä¸¤å¥è¯æ˜¯å¦è¯­ä¹‰ç›¸ä¼¼ã€‚\\n\\nå¥1ï¼šæˆ‘æœ€è¿‘å’³å—½å¾—å‰å®³ã€‚\\nå¥2ï¼šæˆ‘è€æ˜¯å’³å—½ã€‚\"),\n",
    "    (\"KUAKE-QIC\", \"è¯·åˆ¤æ–­ä¸‹é¢çš„é—®é¢˜å±äºå“ªä¸€ç±»ã€‚\\n\\né—®é¢˜ï¼šè¯·é—®å°¿è›‹ç™½1+ä¸¥é‡å—ï¼Ÿ\"),\n",
    "    (\"MedDG\", \"åŒ»ç”Ÿä½ å¥½ï¼Œæˆ‘è‚šå­ç–¼ã€‚ä½ è§‰å¾—ä»€ä¹ˆåŸå› ï¼Ÿ\"),\n",
    "    (\"IMCS-V2-MRG\", \"è¯·ç”Ÿæˆä¸»è¯‰ã€ç°ç—…å²ã€è¯Šæ–­å’Œå»ºè®®ï¼š\\n\\næè¿°ï¼šå°å­©è…¹æ³»ä¸¤å¤©ï¼Œå¤§ä¾¿æ¬¡æ•°å¢å¤šã€‚\")\n",
    "]\n",
    "\n",
    "# === 3. æ‰¹é‡æ¨ç†å¹¶å±•ç¤ºç»“æœ ===\n",
    "for task_name, prompt in prompts:\n",
    "    print(f\"=== [{task_name}] ===\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True, temperature=0.7,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    print(f\"ğŸ“ Prompt:\\n{prompt}\")\n",
    "    print(f\"ğŸ¤– æ¨¡å‹å›å¤:\\n{answer}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea73cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822f287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0789c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ab380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "raw_path = \"./processed/train_converted.jsonl\"\n",
    "filtered_path = \"./processed/train_top_task.jsonl\"\n",
    "\n",
    "# 1) ç»Ÿè®¡æ¯ç§ instruction å‡ºç°æ¬¡æ•°\n",
    "instr_counter = Counter()\n",
    "samples_by_instr = defaultdict(list)\n",
    "\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        sample = json.loads(line)\n",
    "        instr = sample.get(\"instruction\", \"\").strip()\n",
    "        instr_counter[instr] += 1\n",
    "        samples_by_instr[instr].append(sample)\n",
    "\n",
    "# 2) æ‰¾åˆ°å‡ºç°æ¬¡æ•°æœ€å¤šçš„ instruction\n",
    "top_instr, top_count = instr_counter.most_common(1)[0]\n",
    "top_samples = samples_by_instr[top_instr]\n",
    "\n",
    "print(f\"æœ€å¸¸è§ instruction:\\n{top_instr}\\nå‡ºç°æ¬¡æ•°: {top_count}\")\n",
    "\n",
    "# 3) å°†å¯¹åº”æ ·æœ¬å†™å…¥æ–° jsonl\n",
    "with open(filtered_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in top_samples:\n",
    "        f.write(json.dumps(s, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\nå·²å°† {len(top_samples)} æ¡æ ·æœ¬ä¿å­˜åˆ° {filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# ä»£ç  Cellï¼šä» dev_converted.jsonl ä¸­æå–æŒ‡å®šä»»åŠ¡å¹¶ä¿å­˜ä¸º dev_top_task.jsonl\n",
    "input_file = './processed/dev_converted.jsonl'\n",
    "output_file = './processed/dev_top_task.jsonl'\n",
    "\n",
    "count = 0\n",
    "with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', encoding='utf-8') as fout:\n",
    "    for line in fin:\n",
    "        obj = json.loads(line)\n",
    "        if obj.get('instruction', '').startswith(\n",
    "            \"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\"\n",
    "        ):\n",
    "            fout.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Filtered {count} records into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2abccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LoRA fine-tune Qwen-0.5B with BF16, real-time loss plotting, CSV logging, and save-on-terminate ===\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# â”€â”€â”€ 0) Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "output_dir = \"lora_ckpt\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ 1) Prepare Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def concat(example):\n",
    "    example[\"text\"] = example[\"instruction\"] + \"\\n\" + example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "    return example\n",
    "\n",
    "raw_ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"./processed/train_top_task.jsonl\",\n",
    "        \"validation\": \"./processed/dev_top_task.jsonl\"\n",
    "    }\n",
    ").map(concat)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=1024)\n",
    "\n",
    "tok_ds = raw_ds.map(tok_fn, batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# â”€â”€â”€ 2) LoRA Adapter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# â”€â”€â”€ 3) Callback for Loss Logging & Plotting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class LossCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        # Prepare CSV\n",
    "        self.csv_file = open(csv_path, 'w', newline='', encoding='utf-8')\n",
    "        self.csv_writer = csv.writer(self.csv_file)\n",
    "        self.csv_writer.writerow(['step', 'loss'])\n",
    "        # Prepare plot\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.line, = self.ax.plot([], [], lw=2)\n",
    "        self.ax.set_xlabel('Step')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.set_title('Training Loss')\n",
    "        self.steps, self.losses = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            step = state.global_step\n",
    "            loss = logs[\"loss\"]\n",
    "            self.steps.append(step)\n",
    "            self.losses.append(loss)\n",
    "            # write to CSV\n",
    "            self.csv_writer.writerow([step, loss])\n",
    "            self.csv_file.flush()\n",
    "            # update plot\n",
    "            self.line.set_data(self.steps, self.losses)\n",
    "            self.ax.relim()\n",
    "            self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw()\n",
    "            self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        self.csv_file.close()\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "loss_cb = LossCallback(csv_path=os.path.join(output_dir, \"loss.csv\"))\n",
    "\n",
    "# â”€â”€â”€ 4) Training Arguments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"adamw_torch_fused\"\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ 5) Trainer Init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[loss_cb]\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ 6) Train with Interrupt Handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"âš ï¸ Training interrupted. Saving current adapter and tokenizer...\")\n",
    "    trainer.save_model(os.path.join(output_dir, \"interrupted\"))\n",
    "    tokenizer.save_pretrained(os.path.join(output_dir, \"interrupted\"))\n",
    "finally:\n",
    "    print(\"âœ… Training finished. Artifacts and loss logs are in:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d70661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c48b6808864469a876dec0acf0a7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:693: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9107, 'grad_norm': 1.71875, 'learning_rate': 0.00019786324786324788, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd99204e76054680b86c34157f069228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.735177516937256, 'eval_runtime': 187.3612, 'eval_samples_per_second': 4.27, 'eval_steps_per_second': 0.534, 'epoch': 0.03}\n",
      "{'loss': 1.8781, 'grad_norm': 2.25, 'learning_rate': 0.00019572649572649573, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de87d66066f4c9b8364b1c27507ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5323009490966797, 'eval_runtime': 186.7719, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.06}\n",
      "{'loss': 1.2013, 'grad_norm': 1.1640625, 'learning_rate': 0.0001935897435897436, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc16465ea5347cc887f29b265ec75ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.538970708847046, 'eval_runtime': 186.5812, 'eval_samples_per_second': 4.288, 'eval_steps_per_second': 0.536, 'epoch': 0.1}\n",
      "{'loss': 0.9408, 'grad_norm': 1.2578125, 'learning_rate': 0.00019145299145299148, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07527ee3c0ae4dc8a647cb8de0f4d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5759494304656982, 'eval_runtime': 186.7406, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 0.13}\n",
      "{'loss': 0.9613, 'grad_norm': 0.8203125, 'learning_rate': 0.00018931623931623933, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d60bc8830453294c4e6be65295507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6332669258117676, 'eval_runtime': 186.6771, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.16}\n",
      "{'loss': 0.8357, 'grad_norm': 0.75, 'learning_rate': 0.0001871794871794872, 'epoch': 0.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09f3a7d9934447fb0d90711966c2084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6640784740448, 'eval_runtime': 186.8481, 'eval_samples_per_second': 4.282, 'eval_steps_per_second': 0.535, 'epoch': 0.19}\n",
      "{'loss': 0.898, 'grad_norm': 0.921875, 'learning_rate': 0.00018504273504273505, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950df323064e42b4a2b1d34a81208944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.705317497253418, 'eval_runtime': 186.2823, 'eval_samples_per_second': 4.295, 'eval_steps_per_second': 0.537, 'epoch': 0.22}\n",
      "{'loss': 0.8569, 'grad_norm': 0.70703125, 'learning_rate': 0.00018290598290598292, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950255f71274439db42b60e34e2d3940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7448487281799316, 'eval_runtime': 186.6816, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.26}\n",
      "{'loss': 0.8168, 'grad_norm': 0.68359375, 'learning_rate': 0.00018076923076923077, 'epoch': 0.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096ecab4706b4c06bbab5c81ede9421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.687802791595459, 'eval_runtime': 186.6158, 'eval_samples_per_second': 4.287, 'eval_steps_per_second': 0.536, 'epoch': 0.29}\n",
      "{'loss': 0.8639, 'grad_norm': 0.62109375, 'learning_rate': 0.00017863247863247864, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1051762ef84ea49219e6168d011fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7188711166381836, 'eval_runtime': 186.5305, 'eval_samples_per_second': 4.289, 'eval_steps_per_second': 0.536, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8479, 'grad_norm': 0.53515625, 'learning_rate': 0.0001764957264957265, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598125594eff442394665f473058f2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.735438346862793, 'eval_runtime': 186.7905, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.35}\n",
      "{'loss': 0.8449, 'grad_norm': 0.5703125, 'learning_rate': 0.00017435897435897436, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0a5c97083f4efbbc6a3f7db4bfaf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7648589611053467, 'eval_runtime': 186.744, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 0.38}\n",
      "{'loss': 0.8207, 'grad_norm': 0.61328125, 'learning_rate': 0.00017222222222222224, 'epoch': 0.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dd7e6044854d939ae53b2f82577204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7146999835968018, 'eval_runtime': 186.8528, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 0.535, 'epoch': 0.42}\n",
      "{'loss': 0.7931, 'grad_norm': 0.62109375, 'learning_rate': 0.00017008547008547008, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1baf62eb9446cf97a57d5f18969c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7718944549560547, 'eval_runtime': 186.6242, 'eval_samples_per_second': 4.287, 'eval_steps_per_second': 0.536, 'epoch': 0.45}\n",
      "{'loss': 0.7273, 'grad_norm': 0.58984375, 'learning_rate': 0.00016794871794871796, 'epoch': 0.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05753440b4274eddbd30b29b7fc689ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7787740230560303, 'eval_runtime': 186.775, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8334, 'grad_norm': 0.56640625, 'learning_rate': 0.00016581196581196583, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aba03219024f8688c7131463a5fb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.773144483566284, 'eval_runtime': 186.4368, 'eval_samples_per_second': 4.291, 'eval_steps_per_second': 0.536, 'epoch': 0.51}\n",
      "{'loss': 0.7739, 'grad_norm': 0.44140625, 'learning_rate': 0.00016367521367521368, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd567fe37d0a420cb34243afb4428e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7180967330932617, 'eval_runtime': 186.7085, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.54}\n",
      "{'loss': 0.8224, 'grad_norm': 0.451171875, 'learning_rate': 0.00016153846153846155, 'epoch': 0.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f947a930f46e0b3747c0ba323e2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7706716060638428, 'eval_runtime': 186.3628, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.58}\n",
      "{'loss': 0.8268, 'grad_norm': 0.5078125, 'learning_rate': 0.00015940170940170943, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a3bb0dcf0741bba4e35b7efa045100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8255133628845215, 'eval_runtime': 186.4132, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.536, 'epoch': 0.61}\n",
      "{'loss': 0.8068, 'grad_norm': 0.5703125, 'learning_rate': 0.00015726495726495727, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c8e047fb0b46ecb6bb050d0d1b841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766544818878174, 'eval_runtime': 186.7523, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8159, 'grad_norm': 0.50390625, 'learning_rate': 0.00015512820512820515, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72447090720245b28159b9dc04a20ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.761665105819702, 'eval_runtime': 186.6988, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.67}\n",
      "{'loss': 0.7404, 'grad_norm': 0.53125, 'learning_rate': 0.000152991452991453, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb8df13673410784fe29ab41c89ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7524895668029785, 'eval_runtime': 186.7093, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.7}\n",
      "{'loss': 0.7716, 'grad_norm': 0.49609375, 'learning_rate': 0.00015085470085470087, 'epoch': 0.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64af5b9d73024f44a8b74317b5e01a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.782177448272705, 'eval_runtime': 186.6705, 'eval_samples_per_second': 4.286, 'eval_steps_per_second': 0.536, 'epoch': 0.74}\n",
      "{'loss': 0.7793, 'grad_norm': 0.59375, 'learning_rate': 0.00014871794871794872, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5d3efb2ee4ec5986bfb143487e0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.758836030960083, 'eval_runtime': 186.481, 'eval_samples_per_second': 4.29, 'eval_steps_per_second': 0.536, 'epoch': 0.77}\n",
      "{'loss': 0.8199, 'grad_norm': 0.48046875, 'learning_rate': 0.0001465811965811966, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eb743b6e1a46c0859b7baf155b7424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7495827674865723, 'eval_runtime': 186.7246, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7212, 'grad_norm': 0.490234375, 'learning_rate': 0.00014444444444444444, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62ab155766241ac8f8ffc1bbacdd116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7804272174835205, 'eval_runtime': 186.3579, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.83}\n",
      "{'loss': 0.7921, 'grad_norm': 0.482421875, 'learning_rate': 0.0001423076923076923, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16c928a67cb4c8e9562605a176c5793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.738548994064331, 'eval_runtime': 186.6649, 'eval_samples_per_second': 4.286, 'eval_steps_per_second': 0.536, 'epoch': 0.86}\n",
      "{'loss': 0.7646, 'grad_norm': 0.578125, 'learning_rate': 0.00014017094017094016, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e12beea55364e03ae3f7f39e8b2413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.774688482284546, 'eval_runtime': 186.7072, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 0.9}\n",
      "{'loss': 0.7924, 'grad_norm': 0.51953125, 'learning_rate': 0.00013803418803418803, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176d6330ad584ad9b584da6dfd49af6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7493133544921875, 'eval_runtime': 186.8936, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 0.535, 'epoch': 0.93}\n",
      "{'loss': 0.8439, 'grad_norm': 0.58203125, 'learning_rate': 0.0001358974358974359, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44e9ab6c0ec41b0b79bba20954b94d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.756263494491577, 'eval_runtime': 186.3636, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7677, 'grad_norm': 0.56640625, 'learning_rate': 0.00013376068376068375, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6a154447146de8ce09ae02b1e260e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.787390947341919, 'eval_runtime': 186.5364, 'eval_samples_per_second': 4.289, 'eval_steps_per_second': 0.536, 'epoch': 0.99}\n",
      "{'loss': 0.786, 'grad_norm': 0.47265625, 'learning_rate': 0.00013162393162393163, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6338a1f00e7d47e4b0a1df2fc47e5985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.762009859085083, 'eval_runtime': 186.4123, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.536, 'epoch': 1.02}\n",
      "{'loss': 0.7814, 'grad_norm': 0.55859375, 'learning_rate': 0.0001294871794871795, 'epoch': 1.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b837e435a852495886449ea20a74c9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.797741174697876, 'eval_runtime': 186.8079, 'eval_samples_per_second': 4.282, 'eval_steps_per_second': 0.535, 'epoch': 1.06}\n",
      "{'loss': 0.7769, 'grad_norm': 0.6953125, 'learning_rate': 0.00012735042735042735, 'epoch': 1.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b64a2545d5f47f3a9ae9d8ddb18f5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7983739376068115, 'eval_runtime': 186.7691, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.09}\n",
      "{'loss': 0.7823, 'grad_norm': 0.5859375, 'learning_rate': 0.00012521367521367522, 'epoch': 1.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812e49ca82a84a80829bb7f7053e7e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7533841133117676, 'eval_runtime': 186.6762, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7323, 'grad_norm': 0.515625, 'learning_rate': 0.0001230769230769231, 'epoch': 1.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aba69706d24a23bb11ad0d2696a55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.809715986251831, 'eval_runtime': 186.684, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.15}\n",
      "{'loss': 0.783, 'grad_norm': 0.5703125, 'learning_rate': 0.00012094017094017094, 'epoch': 1.18}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a571b9cb2745728c3b6c962133c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7659966945648193, 'eval_runtime': 186.7962, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.18}\n",
      "{'loss': 0.7701, 'grad_norm': 0.5, 'learning_rate': 0.0001188034188034188, 'epoch': 1.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d0cf1fab9e488a8c5cca31e11125b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7735137939453125, 'eval_runtime': 186.315, 'eval_samples_per_second': 4.294, 'eval_steps_per_second': 0.537, 'epoch': 1.22}\n",
      "{'loss': 0.7415, 'grad_norm': 0.578125, 'learning_rate': 0.00011666666666666668, 'epoch': 1.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f04588bd47740a1b6399f1923b6dc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8284246921539307, 'eval_runtime': 186.7429, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.25}\n",
      "{'loss': 0.7722, 'grad_norm': 0.5234375, 'learning_rate': 0.00011452991452991453, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74803f7b791846448361ca2acd8c6c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.817128896713257, 'eval_runtime': 186.3148, 'eval_samples_per_second': 4.294, 'eval_steps_per_second': 0.537, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7603, 'grad_norm': 0.484375, 'learning_rate': 0.0001123931623931624, 'epoch': 1.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36559c635ca4523b8a16397eefb540a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7782318592071533, 'eval_runtime': 186.3396, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.31}\n",
      "{'loss': 0.7973, 'grad_norm': 0.5625, 'learning_rate': 0.00011025641025641027, 'epoch': 1.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a021ff74069462d8446ba1476000f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7732274532318115, 'eval_runtime': 186.7442, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.34}\n",
      "{'loss': 0.7922, 'grad_norm': 0.5390625, 'learning_rate': 0.00010811965811965812, 'epoch': 1.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc23350c49c47d1af2266b4a59e4253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.788694143295288, 'eval_runtime': 186.7546, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.38}\n",
      "{'loss': 0.7502, 'grad_norm': 0.51953125, 'learning_rate': 0.000105982905982906, 'epoch': 1.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7618f2ea0d54470da2c63df5b2dbd809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.790432929992676, 'eval_runtime': 186.7569, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.41}\n",
      "{'loss': 0.8175, 'grad_norm': 0.515625, 'learning_rate': 0.00010384615384615386, 'epoch': 1.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c0e407458408ea67faec678819ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766448974609375, 'eval_runtime': 186.3294, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8247, 'grad_norm': 0.51953125, 'learning_rate': 0.0001017094017094017, 'epoch': 1.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efde6793f14545f2b8988aa07c6d80dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8005406856536865, 'eval_runtime': 186.7484, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.47}\n",
      "{'loss': 0.7404, 'grad_norm': 0.609375, 'learning_rate': 9.957264957264958e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031b3c1377f3498c9ae193a90a39e4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7964980602264404, 'eval_runtime': 186.7933, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.5}\n",
      "{'loss': 0.7168, 'grad_norm': 0.498046875, 'learning_rate': 9.743589743589744e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91459faf00b4035bb08e4097d61ff37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.799997568130493, 'eval_runtime': 186.4422, 'eval_samples_per_second': 4.291, 'eval_steps_per_second': 0.536, 'epoch': 1.54}\n",
      "{'loss': 0.7823, 'grad_norm': 0.49609375, 'learning_rate': 9.52991452991453e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951483e6f0646bf9469657b0bf132f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8017852306365967, 'eval_runtime': 186.7516, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.57}\n",
      "{'loss': 0.7768, 'grad_norm': 0.5859375, 'learning_rate': 9.316239316239317e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c3683c5a724dfdaed4ff9fcfffbbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8386521339416504, 'eval_runtime': 186.7496, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7936, 'grad_norm': 0.5234375, 'learning_rate': 9.102564102564103e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5bbc12e8449de9f511249a5bdb6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.810772180557251, 'eval_runtime': 186.7136, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.63}\n",
      "{'loss': 0.7243, 'grad_norm': 0.54296875, 'learning_rate': 8.888888888888889e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279a531fae144f2b98830b4935c6d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8049535751342773, 'eval_runtime': 186.7393, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.536, 'epoch': 1.66}\n",
      "{'loss': 0.7819, 'grad_norm': 0.498046875, 'learning_rate': 8.675213675213675e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6571deb9fc4c4dc0aabee12ee62b2750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.789511203765869, 'eval_runtime': 186.786, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.7}\n",
      "{'loss': 0.7916, 'grad_norm': 0.578125, 'learning_rate': 8.461538461538461e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7179b6ae3b74488b86f7d5671df314bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.773860454559326, 'eval_runtime': 186.7738, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.73}\n",
      "{'loss': 0.8004, 'grad_norm': 0.5625, 'learning_rate': 8.247863247863247e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28ac670243b407999935b068c1d09c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7844290733337402, 'eval_runtime': 186.7756, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8128, 'grad_norm': 0.54296875, 'learning_rate': 8.034188034188035e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d2d3ec799e4266a96eb1f8b84796da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8049683570861816, 'eval_runtime': 186.7596, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 1.79}\n",
      "{'loss': 0.7574, 'grad_norm': 0.55078125, 'learning_rate': 7.820512820512821e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad7ada512064c21967ec7d888f503a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.806752920150757, 'eval_runtime': 186.7021, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.82}\n",
      "{'loss': 0.7963, 'grad_norm': 0.640625, 'learning_rate': 7.606837606837607e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e224eae1fa471eb62191d91550a326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8106603622436523, 'eval_runtime': 186.3376, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.537, 'epoch': 1.86}\n",
      "{'loss': 0.6968, 'grad_norm': 0.5078125, 'learning_rate': 7.393162393162394e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4db7ce622c4908bf7c4f3eef792372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.807821273803711, 'eval_runtime': 186.711, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 1.89}\n",
      "{'loss': 0.7693, 'grad_norm': 0.52734375, 'learning_rate': 7.17948717948718e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18eaea565c4498595702396f80a2390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7869362831115723, 'eval_runtime': 186.8017, 'eval_samples_per_second': 4.283, 'eval_steps_per_second': 0.535, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7566, 'grad_norm': 0.5234375, 'learning_rate': 6.965811965811965e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dbd282172741db9e3021cb19812f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.78584361076355, 'eval_runtime': 186.3813, 'eval_samples_per_second': 4.292, 'eval_steps_per_second': 0.537, 'epoch': 1.95}\n",
      "{'loss': 0.7394, 'grad_norm': 0.5, 'learning_rate': 6.752136752136753e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b11a01376e744038824db46a6e5fbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7991693019866943, 'eval_runtime': 186.5705, 'eval_samples_per_second': 4.288, 'eval_steps_per_second': 0.536, 'epoch': 1.98}\n",
      "{'loss': 0.779, 'grad_norm': 0.53125, 'learning_rate': 6.538461538461539e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e51300325bb47a8ac4e2eb37a4716f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.801422119140625, 'eval_runtime': 186.7008, 'eval_samples_per_second': 4.285, 'eval_steps_per_second': 0.536, 'epoch': 2.02}\n",
      "{'loss': 0.7889, 'grad_norm': 0.53515625, 'learning_rate': 6.324786324786325e-05, 'epoch': 2.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3affd2446224d27802363a2f2d002fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.791327476501465, 'eval_runtime': 186.7566, 'eval_samples_per_second': 4.284, 'eval_steps_per_second': 0.535, 'epoch': 2.05}\n",
      "{'loss': 0.7867, 'grad_norm': 0.5625, 'learning_rate': 6.111111111111112e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20329fdc30e4bd79740a263f1c6fe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8012540340423584, 'eval_runtime': 191.3033, 'eval_samples_per_second': 4.182, 'eval_steps_per_second': 0.523, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7471, 'grad_norm': 0.52734375, 'learning_rate': 5.897435897435898e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b30ceebfb3c4193a2c12bca9ee63bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.817230224609375, 'eval_runtime': 196.612, 'eval_samples_per_second': 4.069, 'eval_steps_per_second': 0.509, 'epoch': 2.11}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m\n\u001b[0;32m    111\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    112\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    113\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[loss_cb]\n\u001b[0;32m    118\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# 7) å¯åŠ¨è®­ç»ƒ\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2209\u001b[0m ):\n\u001b[0;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\transformers\\trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\accelerate\\accelerator.py:2013\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2013\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === æ›´æ–°ï¼šæ¯éš” step è®°å½• eval lossï¼ˆæ›´å°é—´éš”ï¼‰ï¼Œå¹¶å®æ—¶ç”»å›¾ & å­˜ CSV ===\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer, TrainerCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import os, csv, matplotlib.pyplot as plt\n",
    "\n",
    "# 0) è¾“å‡ºç›®å½•\n",
    "output_dir = \"lora_ckpt2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1) åŠ è½½æ¨¡å‹ä¸ tokenizer\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2) æ•°æ®å¤„ç†ï¼ˆç•¥ï¼Œä¿æŒä¸ä¹‹å‰ç›¸åŒï¼‰\n",
    "def concat(ex): ex[\"text\"] = ex[\"instruction\"]+\"\\n\"+ex[\"input\"]+\"\\n\"+ex[\"output\"]; return ex\n",
    "\n",
    "raw_ds = load_dataset(\"json\",\n",
    "    data_files={\"train\":\"./processed/train_top_task.jsonl\",\n",
    "                \"validation\":\"./processed/dev_top_task.jsonl\"}\n",
    ").map(concat)\n",
    "\n",
    "tok_ds = raw_ds.map(lambda b: tokenizer(b[\"text\"], truncation=True, max_length=1024),\n",
    "                   batched=True, remove_columns=raw_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# 3) æ’å…¥ LoRA\n",
    "lora_cfg = LoraConfig(r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "\n",
    "# 4) Callbackï¼šåŒæ—¶è®°å½• train/eval loss\n",
    "class LossCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        # æ‰“å¼€ CSV\n",
    "        self.csv = open(csv_path, 'w', newline='', encoding='utf-8')\n",
    "        self.writer = csv.writer(self.csv)\n",
    "        self.writer.writerow(['step','type','loss'])\n",
    "        # ç”»å¸ƒ\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.line_t, = self.ax.plot([], [], label=\"train\")\n",
    "        self.line_v, = self.ax.plot([], [], label=\"eval\")\n",
    "        self.ax.set_xlabel(\"Step\"); self.ax.set_ylabel(\"Loss\")\n",
    "        self.ax.legend()\n",
    "        self.st_t, self.ls_t = [], []\n",
    "        self.st_v, self.ls_v = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kw):\n",
    "        if logs and \"loss\" in logs:\n",
    "            step, loss = state.global_step, logs[\"loss\"]\n",
    "            self.st_t.append(step); self.ls_t.append(loss)\n",
    "            self.writer.writerow([step, \"train\", loss]); self.csv.flush()\n",
    "            self.line_t.set_data(self.st_t, self.ls_t)\n",
    "            self.ax.relim(); self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw(); self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kw):\n",
    "        if metrics and \"eval_loss\" in metrics:\n",
    "            step, loss = state.global_step, metrics[\"eval_loss\"]\n",
    "            self.st_v.append(step); self.ls_v.append(loss)\n",
    "            self.writer.writerow([step, \"eval\", loss]); self.csv.flush()\n",
    "            self.line_v.set_data(self.st_v, self.ls_v)\n",
    "            self.ax.relim(); self.ax.autoscale_view()\n",
    "            self.fig.canvas.draw(); self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_train_end(self, *args, **kw):\n",
    "        self.csv.close(); plt.ioff(); plt.show()\n",
    "\n",
    "loss_cb = LossCallback(os.path.join(output_dir, \"loss_log.csv\"))\n",
    "\n",
    "# 5) TrainingArgumentsï¼šstep è¯„ä¼°\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True, fp16=False,\n",
    "    logging_steps=10,              # æ¯ 20 æ­¥è®°å½• train loss\n",
    "    evaluation_strategy=\"steps\",  \n",
    "    eval_steps=10,                 # æ¯ 50 æ­¥è·‘ä¸€æ¬¡ validation\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    optim=\"adamw_torch_fused\"\n",
    ")\n",
    "\n",
    "# 6) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[loss_cb]\n",
    ")\n",
    "\n",
    "# 7) å¯åŠ¨è®­ç»ƒ\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dadcf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 201328128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ å¼€å§‹åˆå¹¶ LoRA æƒé‡ â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ä¿å­˜åˆ° qwen05_promptcblue_merged2\n",
      "ğŸ—£ï¸ æ¨ç†ç»“æœ: ____\n",
      "A. æ€¥æ€§æ”¯æ°”ç®¡ç‚\n",
      "B. è‚ºéƒ¨æ„ŸæŸ“\n",
      "C. æ”¯æ°”ç®¡è‚ºç‚\n",
      "D. å’³å—½å˜å¼‚æ€§å“®å–˜\n",
      "ç­”æ¡ˆ:\n",
      "\n",
      "B\n",
      "\n",
      "å…³äºèƒ¸è…”ç§¯æ¶²çš„æè¿°ï¼Œä¸‹åˆ—å“ªé¡¹æ˜¯é”™è¯¯çš„ï¼š\n",
      "A. ç”±äºæ·‹å·´ç»†èƒå‡å°‘\n"
     ]
    }
   ],
   "source": [
    "# === åˆå¹¶ LoRA + åŸºåº§æƒé‡ï¼Œå¾—åˆ°å¯ç‹¬ç«‹æ¨ç†æ¨¡å‹ ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch, os, shutil\n",
    "\n",
    "# 1) è·¯å¾„é…ç½®\n",
    "base_model_id   = \"Qwen/Qwen2.5-0.5B-Instruct\"   # åŸå§‹åŸºåº§\n",
    "lora_adapter_dir = \"lora_ckpt2/checkpoint-650\"             # è®­ç»ƒå®Œçš„ LoRA ç›®å½•\n",
    "merged_dir       = \"qwen05_promptcblue_merged2\"   # è¦ä¿å­˜çš„æ–°ç›®å½•\n",
    "\n",
    "# 2) åŠ è½½åŸºåº§ & LoRA\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, lora_adapter_dir)\n",
    "print(\"ğŸ”„ å¼€å§‹åˆå¹¶ LoRA æƒé‡ â€¦\")\n",
    "model = model.merge_and_unload()   # â­ ä¸€æ­¥åˆ°ä½\n",
    "\n",
    "# 3) ä¿å­˜ï¼ˆå« tokenizerï¼‰\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "print(f\"âœ… å·²ä¿å­˜åˆ° {merged_dir}\")\n",
    "\n",
    "# 4) ï¼ˆå¯é€‰ï¼‰å¿«é€Ÿ sanity check æ¨ç†\n",
    "prompt = \"æ‚£è€…å‡ºç°å’³å—½ã€å‘çƒ­ã€å‘¼å¸å›°éš¾ï¼Œåº”è€ƒè™‘å“ªç§æœ€å¯èƒ½çš„åˆæ­¥è¯Šæ–­ï¼Ÿ\"\n",
    "ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"ğŸ—£ï¸ æ¨ç†ç»“æœ:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—£ï¸ æ¨ç†ç»“æœ: å’Œè¡€å¸¸è§„çœ‹çœ‹ã€‚\n",
      "ç—‡çŠ¶é˜´é˜³æ€§é€‰é¡¹ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶ï¼Œæ‚£æœ‰è¯¥ç—‡çŠ¶ï¼Œæ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
      "å½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶åŠå…¶é˜´é˜³æ€§åˆ¤æ–­ä¸ºï¼š\n",
      "ç‚ç—‡ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
      "è‚åŠŸèƒ½ï¼šæ‚£æœ‰è¯¥ç—‡çŠ¶\n",
      "è¡€å¸¸è§„ï¼šæ‚£æœ‰è¯¥ç—‡çŠ¶\n",
      "è‚åŠŸèƒ½ï¼š\n"
     ]
    }
   ],
   "source": [
    "train1 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "æ‰¾å‡ºå½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šå¥¶å¥¶\n",
    "åŒ»ç”Ÿï¼šå¤§ä¾¿ä»€ä¹ˆæ ·çš„ï¼Ÿæœ‰å‘³å—ï¼Ÿ\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "æ‚£è€…ï¼šæœ‰å¤§ä¾¿ä¸€ç›´æœ‰å‘³å‘³é“æœ‰çµ®çŠ¶ç‰©\"\"\"\n",
    "\n",
    "\n",
    "train2 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "æ‰¾å‡ºå½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šå®å®å’³å—½æ˜¯ç™½å¤©ä¸¥é‡è¿˜æ˜¯å¤œé—´ä¸¥é‡\n",
    "æ‚£è€…ï¼šç™½å¤©\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ‰æ²¡æœ‰å–˜é¸£æ€¥ç—‡çŠ¶\"\"\"\n",
    "\n",
    "train3 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "æ‰¾å‡ºå½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ€è¿‘å¤´ç—›å‰å®³å—ï¼Ÿæœ‰æ²¡æœ‰å‘•åï¼Ÿ\n",
    "æ‚£è€…ï¼šå¶å°”å¤´æ™•ï¼Œæœ‰æ—¶å€™æ¶å¿ƒ\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šå‘•åçš„é¢‘ç‡æ˜¯å¤šå°‘ï¼Ÿ\"\"\"\n",
    "\n",
    "train4 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "æ‰¾å‡ºå½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šçœ¼ç›å‘é»„å¤šä¹…äº†ï¼Ÿ\n",
    "æ‚£è€…ï¼šå¤§æ¦‚ä¸¤å¤©\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ‰å‘ç‚å—ï¼Ÿ\"\"\"\n",
    "\n",
    "train5 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "æ‰¾å‡ºå½“å‰å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šä»–æœ‰æ²¡æœ‰ç‚ç—‡ï¼Ÿ\n",
    "æ‚£è€…ï¼šè‚åŠŸèƒ½æ£€æŸ¥æœ‰ç‚¹é«˜\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šå»ºè®®æŸ¥ä¸ªè‚åŠŸèƒ½\"\"\"\n",
    "\n",
    "dev1 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "è¯†åˆ«ä»¥ä¸‹å¯¹è¯ä¸­çš„ç—‡çŠ¶ï¼Œå¹¶åˆ¤æ–­å…¶é˜´é˜³æ€§ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šä½ ç°åœ¨å’³å—½æ€ä¹ˆæ ·\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "æ‚£è€…ï¼šæ²¡æœ‰å’³å—½äº†ï¼Œå‘çƒ§é€€äº†\"\"\"\n",
    "dev2 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ‰æ²¡æœ‰å‘¼å¸å›°éš¾æˆ–è€…å–˜ä¸ä¸Šæ°”çš„æƒ…å†µï¼Ÿ\n",
    "æ‚£è€…ï¼šæ²¡æœ‰ï¼Œå°±æ˜¯ç—°å¤šä¸€ç‚¹\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šé‚£åº”è¯¥ä¸æ˜¯å–˜æ¯é—®é¢˜\"\"\"\n",
    "dev3 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "è¯·åˆ¤æ–­å½“å‰å¯¹è¯ä¸­æåˆ°çš„ç—‡çŠ¶åŠå…¶çŠ¶æ€ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ‰æ²¡æœ‰å¤´æ™•æˆ–è€…å‘•åï¼Ÿ\n",
    "æ‚£è€…ï¼šæœ€è¿‘å¤´æ™•æ¯”è¾ƒæ˜æ˜¾\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šæœ‰æ²¡æœ‰åè¿‡ï¼Ÿ\"\"\"\n",
    "dev4 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "è¯·åˆ¤æ–­â€œç‚ç—‡â€æ˜¯å¦å­˜åœ¨ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šä»–ä¹‹å‰æœ‰å‘ç‚å²å—ï¼Ÿ\n",
    "æ‚£è€…ï¼šæœ‰è¿‡è‚ç‚\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šç°åœ¨è‚åŠŸèƒ½æ¢å¤äº†æ²¡æœ‰\"\"\"\n",
    "\n",
    "dev5 = \"\"\"æ ¹æ®ç»™å®šå†…å®¹ï¼Œåˆ¤æ–­åˆ—å‡ºçš„ä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€é˜´æ€§ã€å…¶ä»–è¿˜æ˜¯ä¸æ ‡æ³¨ã€‚\n",
    "å¯é€‰æ ‡ç­¾ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶, æ‚£æœ‰è¯¥ç—‡çŠ¶, æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç—…äººæ˜¯å¦æ‚£æœ‰è¯¥ç—‡çŠ¶\n",
    "è¯·åˆ¤æ–­æ‚£è€…æ˜¯å¦å­˜åœ¨â€œå–˜æ¯â€ï¼š\n",
    "å¯¹è¯å†å²ï¼š\n",
    "åŒ»ç”Ÿï¼šæ™šä¸Šç¡è§‰ä¼šå–˜ä¸ä¸Šæ°”å—ï¼Ÿ\n",
    "æ‚£è€…ï¼šä¼š\n",
    "å½“å‰å¯¹è¯ï¼š\n",
    "åŒ»ç”Ÿï¼šè€ƒè™‘æœ‰ç‚¹å“®å–˜çš„è¡¨ç°\"\"\"\n",
    "# for i in range(1, 6):\n",
    "#     for prefix in [\"train\", \"dev\"]:\n",
    "#         prompt = eval(f\"{prefix}{i}\")\n",
    "#         ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#         out = model.generate(**ids, max_new_tokens=64)\n",
    "#         print(f\"\\nğŸ§ª {prefix}{i} æ¨ç†ç»“æœ:\\n\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))\n",
    "\n",
    "ids = tokenizer(train5, return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(**ids, max_new_tokens=64)\n",
    "print(\"ğŸ—£ï¸ æ¨ç†ç»“æœ:\", tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c624675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\qwen05_lora\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] train1 æ¨ç†ç»“æœï¼š\n",
      "\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼šæœ‰å¤§ä¾¿ä¸€ç›´æœ‰å‘³å‘³é“æœ‰çµ®çŠ¶ç‰©ï¼ˆé˜³ï¼‰ æ ¹æ®ç»™å‡ºçš„ä¿¡æ¯ï¼Œ\"æœ‰å¤§ä¾¿ä¸€ç›´æœ‰å‘³å‘³é“æœ‰çµ®çŠ¶ç‰©\" è¿™ä¸ªä¸´åºŠå‘ç°å®ä½“æ˜¯é˜³æ€§ã€‚å› æ­¤ï¼Œæœ€ç»ˆç­”æ¡ˆä¸ºé˜³æ€§ã€‚\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] dev1 æ¨ç†ç»“æœï¼š\n",
      "ï¼Œä½†æ˜¯è¿˜æµé¼»æ¶•\n",
      "\n",
      "ç—‡çŠ¶ï¼šå‘çƒ­\n",
      "é˜³æ€§å’Œé˜´æ€§ï¼šå‘çƒ­\n",
      "é˜´é˜³æ€§ï¼šé˜³æ€§å’Œé˜´æ€§\n",
      "æœªæ ‡æ³¨ï¼šæ— \n",
      "ï¼ˆåŒ»ç”Ÿï¼‰: â€œä½ æœ€è¿‘æœ‰æ²¡æœ‰æ„Ÿå†’ï¼Ÿâ€ï¼ˆæ‚£è€…ï¼‰: â€œæ²¡æœ‰ã€‚â€ï¼ˆåŒ»ç”Ÿï¼‰: \"é‚£ä½ èƒ½è¯´ä¸€ä¸‹ä½ çš„ç—‡çŠ¶å—ï¼Ÿ\"ï¼ˆæ‚£è€…\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] train2 æ¨ç†ç»“æœï¼š\n",
      "ï¼Ÿ\n",
      "æ‚£è€…ï¼šæ— \n",
      "\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šå…¶ä»–\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼šé˜´æ€§\n",
      "ä¸´åºŠå‘ç°å®ä½“ï¼š\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] dev2 æ¨ç†ç»“æœï¼š\n",
      "ï¼Œå¯èƒ½æ˜¯æ„Ÿå†’äº†\n",
      "æ‚£è€…ï¼šå—¯\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼šå…¶ä»–\n",
      "\n",
      "ç­”æ¡ˆï¼šå…¶ä»–\n",
      "\n",
      "åŒ»ç”Ÿï¼šè¯·é—®æ‚¨æœ€è¿‘æœ‰è¿‡å’³å—½å—ï¼Ÿå¦‚æœæœ‰çš„è¯ï¼Œè¯·æè¿°ä¸€ä¸‹ã€‚\n",
      "æ‚£è€…ï¼šæ²¡æœ‰ï¼Œå°±æ˜¯å¶å°”å’³å‡ å£°ã€‚\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼šå…¶ä»–\n",
      "\n",
      "ç­”æ¡ˆï¼šå…¶ä»–\n",
      "\n",
      "åŒ»ç”Ÿï¼šé‚£åº”è¯¥æ˜¯æ„Ÿå†’å¼•èµ·çš„å’³å—½ï¼Œå¯ä»¥åƒç‚¹\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] train3 æ¨ç†ç»“æœï¼š\n",
      "ä»Šå¤©å‘•åäº†å‡ æ¬¡ï¼Ÿ\n",
      "æ‚£è€…ï¼šä»Šå¤©æ—©ä¸Šåäº†ä¸¤æ¬¡ã€‚ä»Šå¤©ä¸‹åˆåˆåäº†ä¸€æ¬¡ã€‚\n",
      "[æ²‰é»˜]  \n",
      "åŒ»ç”Ÿï¼šä½ æ˜¯ä¸æ˜¯åƒå¤šäº†ï¼Ÿ\n",
      "æ‚£è€…ï¼šæ²¡åƒå¤ªå¤šï¼Œåªæ˜¯åƒäº†ç‚¹é£Ÿç‰©ã€‚\n",
      "[æ²‰é»˜]\n",
      "åŒ»ç”Ÿï¼šè¿™æ˜¯æ€ä¹ˆå›äº‹å•Šï¼Ÿæˆ‘é—®è¿‡ä½ äº†ã€‚\n",
      "æ‚£è€…ï¼šæˆ‘æ˜¨å¤©æ™šä¸Šå–äº†åŠ\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] dev3 æ¨ç†ç»“æœï¼š\n",
      " \n",
      "æ‚£è€…ï¼šæ²¡\n",
      "\n",
      "å½“å‰è®¨è®ºè¯é¢˜ï¼šæ— \n",
      "å½“å‰æè¿°ç—…æƒ…ï¼šå¤´æ™•æ¶å¿ƒ\n",
      "ç›®å‰å¯ç”¨è¯Šæ–­æ–¹æ³•ï¼šå¤´é¢…CTï¼Œèƒƒé•œæ£€æŸ¥\n",
      "ç›®å‰å¯ç”¨è¯ç‰©æ²»ç–—ï¼šæ­¢åè¯\n",
      "å¯ä»¥æ¨æµ‹å‡ºçš„è¯Šæ–­ï¼šçœ©æ™•ç—‡\n",
      "å¯èƒ½çš„ç—…å› ï¼šé«˜è¡€å‹\n",
      "å¯èƒ½çš„è¯±å› ï¼šåŠ³ç´¯\n",
      "å¯èƒ½\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] train4 æ¨ç†ç»“æœï¼š\n",
      "çœ¼ç›å‘çº¢å—ï¼Ÿ\n",
      "æ‚£è€…ï¼šæ²¡æœ‰\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼š[â€œç³å­”æ•£å¤§â€]\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼š[â€œçœ¼ç‘è‚¿èƒ€â€]\n",
      "\n",
      "ä¸´åºŠå‘ç°ï¼š[â€œè§’è†œæµ‘æµŠâ€] å…¶ä»–\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "é˜´æ€§\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] dev4 æ¨ç†ç»“æœï¼š\n",
      "ï¼Ÿ\n",
      "æ‚£è€…ï¼šç°åœ¨è‚åŠŸèƒ½æ­£å¸¸\n",
      "åŒ»ç”Ÿï¼šé‚£æ‚¨æ˜¯ä¸æ˜¯æœ‰å‘ç‚ç—…å²ï¼Ÿ\n",
      "æ‚£è€…ï¼šæ²¡æœ‰\n",
      "åŒ»ç”Ÿï¼šé‚£ä¹ˆæ‚¨çš„ç‚ç—‡ç›®å‰åº”è¯¥å¤„äºä»€ä¹ˆçŠ¶æ€ï¼Ÿï¼ˆç‚¹å¤´ï¼‰ \n",
      "åŒ»ç”Ÿï¼šå¥½ã€‚é‚£æ‚¨ä»Šå¤©çš„æƒ…å†µæ€ä¹ˆæ ·ï¼Ÿ\n",
      "æ‚£è€…ï¼šæˆ‘æ„Ÿè§‰è¿˜å¥½ã€‚\n",
      "åŒ»ç”Ÿï¼šå¥½çš„ï¼Œé‚£æ‚¨å¯ä»¥å…ˆå›å®¶ä¼‘æ¯å‡ å¤©\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] train5 æ¨ç†ç»“æœï¼š\n",
      "\n",
      "åŒ»ç”Ÿï¼šä½ æœ‰è¿™ä¸ªç—…å—ï¼Ÿ \n",
      "æ‚£è€…ï¼šæ²¡\n",
      "\n",
      "é˜´æ€§ æ ¹æ®ç»™å‡ºçš„å†…å®¹ï¼Œ\"è‚åŠŸèƒ½æ£€æŸ¥æœ‰ç‚¹é«˜\" æ˜¯ä¸€ä¸ªæ˜ç¡®çš„ç—‡çŠ¶æè¿°ã€‚å› æ­¤ï¼Œæ ¹æ® \"è‚åŠŸèƒ½æ£€æŸ¥æœ‰ç‚¹é«˜\" è¿™ä¸€ç—‡çŠ¶ï¼Œæˆ‘ä»¬å¯ä»¥åˆ¤æ–­å‡º \"é˜´æ€§\"ã€‚\n",
      "\n",
      "æœ€ç»ˆç­”æ¡ˆï¼šé˜´æ€§ã€‚\n",
      "\n",
      "ğŸ§ª [åŸå§‹æ¨¡å‹] dev5 æ¨ç†ç»“æœï¼š\n",
      "ï¼Œè¯·é—®ä½ æœ‰è¿‡æ¥è§¦è¿‡æ•æºå—ï¼Ÿï¼ˆæ‚£è€…ç‚¹å¤´ï¼‰é‚£ä½ èƒ½è¯´ä¸€ä¸‹ä½ æœ€è¿‘æœ‰æ²¡æœ‰åƒè¿‡ä»€ä¹ˆå¯¹èº«ä½“æœ‰å®³çš„é£Ÿç‰©å—ï¼Ÿï¼ˆæ‚£è€…ç‚¹ç‚¹å¤´ï¼‰æˆ‘ä¹‹å‰åƒäº†æµ·é²œã€‚è¯·é—®ä½ æœ‰æ²¡æœ‰åƒè¿‡æµ·é²œï¼Ÿï¼ˆæ‚£è€…ç‚¹å¤´ï¼‰\n",
      "åŒ»ç”Ÿï¼šæµ·é²œå¯èƒ½ä¼šå¼•èµ·è¿‡æ•ååº”ã€‚ä½ çš„ç—‡çŠ¶å’Œä¹‹å‰çš„è¿‡æ•å²æœ‰å…³è”\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# 1ï¸âƒ£ åŠ è½½åŸå§‹æœªå¾®è°ƒæ¨¡å‹\n",
    "base_model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ åŠ è½½å‰é¢å®šä¹‰çš„ promptï¼ˆä½ å·²å®šä¹‰ train1~5 å’Œ dev1~5ï¼‰\n",
    "# ç¡®ä¿è¿™äº›å˜é‡å·²ç»å­˜åœ¨äºå½“å‰ç¯å¢ƒä¸­\n",
    "\n",
    "# 3ï¸âƒ£ æ‰¹é‡ç”Ÿæˆå¹¶å±•ç¤ºç»“æœ\n",
    "for i in range(1, 6):\n",
    "    for prefix in [\"train\", \"dev\"]:\n",
    "        prompt = eval(f\"{prefix}{i}\")\n",
    "        ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(**ids, max_new_tokens=64)\n",
    "        output = tokenizer.decode(out[0, ids['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        print(f\"\\nğŸ§ª [åŸå§‹æ¨¡å‹] {prefix}{i} æ¨ç†ç»“æœï¼š\\n{output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a22f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================\n",
    "# # LoRA å¾®è°ƒ Qwen2-0.5B-Instruct â€”â€” åŒ»å­¦ç—‡çŠ¶é˜´é˜³æ€§åˆ¤åˆ«\n",
    "# # æ•°æ®æ–‡ä»¶: /mnt/data/train_top_task.jsonl\n",
    "# # è®­ç»ƒç»“æŸåä¼šæŠŠè®­ç»ƒ loss è®°å½•åˆ° training_log.csv\n",
    "# # å¹¶å®æ—¶ç»˜åˆ¶ loss æ›²çº¿ï¼›æ”¯æŒ Ctrl-C/Interrupt æå‰åœæ­¢å¹¶ä¿å­˜æƒé‡\n",
    "# # ==============================================\n",
    "\n",
    "# import os, json, csv, time, math, torch, matplotlib.pyplot as plt\n",
    "# from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "# from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "# DATA_PATH = \"./processed/train_top_task.jsonl\"      # <-- è‹¥è·¯å¾„ä¸åŒè¯·è‡ªè¡Œä¿®æ”¹\n",
    "# MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "# OUTPUT_DIR = \"./qwen_lora_symptom\"\n",
    "# CSV_LOG = os.path.join(OUTPUT_DIR, \"training_log.csv\")\n",
    "\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# # 1) åŠ è½½æ•°æ®é›†\n",
    "# dataset = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "\n",
    "# # 2) ç®€å• tokenize\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# def preprocess(example):\n",
    "#     prompt = f\"{example['instruction']}\\n\\n{example['input']}\\n\\nç­”æ¡ˆï¼š\"\n",
    "#     example[\"prompt\"] = prompt\n",
    "#     example[\"labels\"] = example[\"output\"]\n",
    "#     return example\n",
    "\n",
    "# dataset = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
    "\n",
    "# def tokenize_func(example):\n",
    "#     model_input = tokenizer(example[\"prompt\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "#     label_ids = tokenizer(example[\"labels\"], truncation=True, max_length=128, padding=\"max_length\")[\"input_ids\"]\n",
    "#     model_input[\"labels\"] = label_ids\n",
    "#     return model_input\n",
    "\n",
    "# tokenized_ds = dataset.map(tokenize_func, batched=False)\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "# # 3) åŠ è½½æ¨¡å‹å¹¶åº”ç”¨ LoRA\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\"\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 4) å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "# args = TrainingArguments(\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     learning_rate=2e-4,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=200,\n",
    "#     save_total_limit=2,\n",
    "#     fp16=True,\n",
    "#     report_to=[],\n",
    "# )\n",
    "\n",
    "# # 5) è‡ªå®šä¹‰ Callbackï¼šè®°å½• loss åˆ° CSV å¹¶å®æ—¶ç”»å›¾\n",
    "# from transformers import TrainerCallback\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "# class LossLoggerCallback(TrainerCallback):\n",
    "#     def __init__(self, csv_path):\n",
    "#         self.csv_path = csv_path\n",
    "#         # csv header\n",
    "#         if not os.path.exists(csv_path):\n",
    "#             with open(csv_path, \"w\", newline=\"\") as f:\n",
    "#                 writer = csv.writer(f); writer.writerow([\"step\", \"loss\"])\n",
    "#         self.losses = []\n",
    "\n",
    "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "#         if logs is None or \"loss\" not in logs:\n",
    "#             return\n",
    "#         step = state.global_step\n",
    "#         loss = logs[\"loss\"]\n",
    "#         self.losses.append((step, loss))\n",
    "#         # append to CSV\n",
    "#         with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "#             csv.writer(f).writerow([step, loss])\n",
    "\n",
    "#         # --- å®æ—¶ç»˜å›¾ ---\n",
    "#         clear_output(wait=True)\n",
    "#         steps, lossv = zip(*self.losses)\n",
    "#         plt.figure(figsize=(6,4))\n",
    "#         plt.plot(steps, lossv, label=\"train loss\")\n",
    "#         plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.title(\"Training Loss\")\n",
    "#         plt.legend(); plt.grid(True)\n",
    "#         display(plt.gcf())\n",
    "#         plt.close()\n",
    "\n",
    "# loss_cb = LossLoggerCallback(CSV_LOG)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=tokenized_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     callbacks=[loss_cb]\n",
    "# )\n",
    "\n",
    "# # 6) è®­ç»ƒå¸¦ try/exceptï¼Œæ”¯æŒ Ctrl-C ä¿å­˜é€€å‡º\n",
    "# try:\n",
    "#     trainer.train()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"âš ï¸ æ‰‹åŠ¨åœæ­¢è®­ç»ƒï¼Œæ­£åœ¨ä¿å­˜æ¨¡å‹æƒé‡...\")\n",
    "#     trainer.save_model(os.path.join(OUTPUT_DIR, \"interrupted\"))\n",
    "#     print(\"âœ… æƒé‡å·²ä¿å­˜åˆ° interrupted/ ï¼Œè®­ç»ƒä¸­æ–­ã€‚\")\n",
    "#     raise\n",
    "\n",
    "# # 7) è®­ç»ƒå®Œæˆåä¿å­˜æœ€ç»ˆæƒé‡\n",
    "# trainer.save_model(os.path.join(OUTPUT_DIR, \"final\"))\n",
    "# print(\"ğŸ è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ° final/ ï¼Œloss è®°å½•åœ¨ training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0743d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, torch, matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM,\n",
    "                          TrainingArguments, Trainer,\n",
    "                          DataCollatorWithPadding, TrainerCallback)\n",
    "from peft import (prepare_model_for_kbit_training, LoraConfig,get_peft_model, TaskType)\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# ===== è·¯å¾„ =====\n",
    "MODEL_NAME   = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "DATA_PATH    = \"./processed/train_top_task.jsonl\"\n",
    "OUTPUT_DIR   = \"./qwen_lora_symptom\"\n",
    "CSV_LOG      = os.path.join(OUTPUT_DIR, \"training_log.csv\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== 1. æ•°æ® =====\n",
    "ds_raw = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "def preprocess(ex):\n",
    "    ex[\"prompt\"] = f'{ex[\"instruction\"]}\\n\\n{ex[\"input\"]}\\n\\nç­”æ¡ˆï¼š'\n",
    "    ex[\"answer\"] = ex[\"output\"]\n",
    "    return ex\n",
    "\n",
    "ds = ds_raw.map(preprocess, remove_columns=ds_raw.column_names)\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    model_in = tokenizer(\n",
    "        ex[\"prompt\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    label_ids = tokenizer(\n",
    "        ex[\"answer\"], truncation=True, max_length=128, padding=\"max_length\"\n",
    "    )[\"input_ids\"]\n",
    "    # æŠŠ padding æ ‡æˆ -100 ä»¥å±è”½ loss\n",
    "    label_ids = [tok if tok != tokenizer.pad_token_id else -100\n",
    "                 for tok in label_ids]\n",
    "    model_in[\"labels\"] = label_ids\n",
    "    return model_in\n",
    "\n",
    "ds_tok = ds.map(tokenize_fn, batched=False)\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=None,\n",
    "                                   return_tensors=\"pt\")\n",
    "\n",
    "# ===== 2. æ¨¡å‹ & LoRA =====\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16,\n",
    "    trust_remote_code=True)\n",
    "base = prepare_model_for_kbit_training(base)\n",
    "\n",
    "lconf = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8, lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(base, lconf)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. è®­ç»ƒå‚æ•° =====\n",
    "args = TrainingArguments(\n",
    "    output_dir          = OUTPUT_DIR,\n",
    "    num_train_epochs    = 3,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    learning_rate       = 2e-4,\n",
    "    logging_steps       = 10,\n",
    "    save_steps          = 200,\n",
    "    save_total_limit    = 2,\n",
    "    fp16                = True,\n",
    "    report_to           = [],\n",
    "    label_names         = [\"labels\"],   # <- å‘Šè¯‰ Trainer ç”¨ labels å­—æ®µ\n",
    ")\n",
    "\n",
    "# ===== 4. Loss è®°å½• & æ›²çº¿ =====\n",
    "class LossPlotCallback(TrainerCallback):\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv = csv_path\n",
    "        if not os.path.exists(self.csv):\n",
    "            with open(self.csv, \"w\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([\"step\", \"loss\"])\n",
    "        self.buf = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kw):\n",
    "        if logs is None or \"loss\" not in logs:\n",
    "            return\n",
    "        step, loss = state.global_step, logs[\"loss\"]\n",
    "        self.buf.append((step, loss))\n",
    "        with open(self.csv, \"a\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow([step, loss])\n",
    "        # å®æ—¶æ›²çº¿\n",
    "        clear_output(wait=True)\n",
    "        xs, ys = zip(*self.buf)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(xs, ys); plt.grid(); plt.xlabel(\"step\"); plt.ylabel(\"loss\")\n",
    "        plt.title(\"Training Loss\"); display(plt.gcf()); plt.close()\n",
    "\n",
    "loss_cb = LossPlotCallback(CSV_LOG)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    callbacks=[loss_cb],\n",
    ")\n",
    "\n",
    "# ===== 5. è®­ç»ƒï¼ˆæ”¯æŒ Ctrl-C ä¿å­˜æƒé‡ï¼‰ =====\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"âš ï¸ æ‰‹åŠ¨åœæ­¢ï¼Œä¿å­˜æƒé‡ä¸­ â€¦\")\n",
    "    trainer.save_model(os.path.join(OUTPUT_DIR, \"interrupted\"))\n",
    "    print(\"âœ… å·²ä¿å­˜è‡³ interrupted/\")\n",
    "    raise\n",
    "\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, \"final\"))\n",
    "print(\"ğŸ è®­ç»ƒå®Œæˆï¼æƒé‡å†™å…¥ final/ ï¼Œloss è®°å½•åœ¨ training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d3187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "109a7257",
   "metadata": {},
   "source": [
    "Label conflicts: The same symptom received conflicting labels,\n",
    "     e.g., â€œå’³å—½ï¼šæ‚£æœ‰è¯¥ç—‡çŠ¶â€ and â€œå’³å—½ï¼šæ²¡æœ‰æ‚£æœ‰è¯¥ç—‡çŠ¶â€ in one output.\n",
    "\n",
    "Symptom duplication: Repetitive entries for the same phrase with no added meaning.\n",
    "     e.g.,â€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜´æ€§â€ï¼Œâ€œé˜³æ€§â€ã€‚\n",
    "\n",
    "Format drift: Outputs sometimes shifted into natural prose,\n",
    "     e.g., â€œæ‚£è€…å¤´ç—›ä¸æ˜æ˜¾ï¼Œåˆæ­¥è€ƒè™‘ä¸ºé˜³æ€§çŠ¶æ€ã€‚â€\n",
    "\n",
    "Non-symptom inclusion: \n",
    "    Phrases like â€œæ²»ç–—å»ºè®®â€ or â€œåçš„é¢‘ç‡æ˜¯å¤šå°‘â€ were misclassified as symptoms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          æ‚£è€…å¯èƒ½å‡ºç°å‘çƒ§å’Œå’³å—½ï¼Œè¯·ç»“åˆä¸´åºŠåˆ¤æ–­ã€‚  \n",
    "          å»ºè®®è¿›è¡Œå¤´é¢…CTæ£€æŸ¥ä»¥æ’é™¤è„‘å‡ºè¡€ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          æ‚£è€…çƒ§å¾—å¾ˆæ˜æ˜¾ï¼Œä¸ºé˜³æ€§ã€‚\n",
    "          è¯¥ç—‡çŠ¶è€ƒè™‘ä¸ºé˜³æ€§ï¼Œæ‚£è€…è¡¨ç°çªå‡ºã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen05_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
